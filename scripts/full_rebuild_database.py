#!/usr/bin/env python3
"""
å®Œæ•´é‡å»ºæ•°æ®åº“ - ä¸€ä½“å¼è„šæœ¬

åŠŸèƒ½ï¼š
1. æ¸…ç©ºæ‰€æœ‰ç–¾ç—…ç›¸å…³è¡¨
2. ä» CSV å¯¼å…¥æ ‡å‡†ç–¾ç—…åº“å’Œæ˜ å°„å…³ç³»
3. åŒæ­¥ diseases è¡¨
4. å¯¼å…¥å†å²æ•°æ®åˆ° disease_records
5. éªŒè¯æ•°æ®å®Œæ•´æ€§

ä¸€æ¬¡è¿è¡Œï¼Œå…¨éƒ¨å®Œæˆï¼
"""
import asyncio
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
import pandas as pd
from typing import Dict, Set

ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(ROOT))

from sqlalchemy import text
from src.core.database import get_db
from src.core.logging import get_logger

logger = get_logger(__name__)


class DatabaseRebuilder:
    def __init__(self, auto_confirm=False):
        self.standard_file = ROOT / "configs/standard_diseases.csv"
        self.mapping_file = ROOT / "configs/cn/disease_mapping.csv"
        self.history_file = ROOT / "data/processed/history_merged.csv"
        self.country_code = "CN"
        self.auto_confirm = auto_confirm
        
    async def run(self):
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®åº“é‡å»ºæµç¨‹"""
        logger.info("=" * 80)
        logger.info("ğŸš€ å®Œæ•´æ•°æ®åº“é‡å»ºæµç¨‹")
        logger.info("=" * 80)
        
        # æ˜¾ç¤ºè­¦å‘Šå’Œç»Ÿè®¡ä¿¡æ¯
        async with get_db() as db:
            await self._show_warning_and_stats(db)
            
            # è¯¢é—®ç¡®è®¤
            if not self.auto_confirm:
                if not self._confirm_rebuild():
                    logger.info("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                    return
            
            logger.info("\n" + "=" * 80)
            logger.info("å¼€å§‹æ‰§è¡Œæ•°æ®åº“é‡å»º...")
            logger.info("=" * 80)
            
            # æ­¥éª¤ 1: æ¸…ç©ºæ•°æ®
            await self.clear_data(db)
            
            # æ­¥éª¤ 2: å¯¼å…¥æ ‡å‡†ç–¾ç—…åº“
            await self.import_standard_diseases(db)
            
            # æ­¥éª¤ 3: å¯¼å…¥ç–¾ç—…æ˜ å°„
            await self.import_disease_mappings(db)
            
            # æ­¥éª¤ 4: åŒæ­¥ diseases è¡¨
            await self.sync_diseases_table(db)
            
            # æ­¥éª¤ 5: å¯¼å…¥å†å²æ•°æ®
            await self.import_history_data(db)
            
            # æ­¥éª¤ 6: éªŒè¯ç»“æœ
            await self.verify_results(db)
            
        logger.info("\n" + "=" * 80)
        logger.info("âœ… æ•°æ®åº“é‡å»ºå®Œæˆï¼")
        logger.info("=" * 80)
    
    async def _show_warning_and_stats(self, db):
        """æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯å’Œå½“å‰æ•°æ®ç»Ÿè®¡"""
        logger.warning("\nâš ï¸  è­¦å‘Šï¼šæ­¤æ“ä½œå°†æ¸…ç©ºä»¥ä¸‹æ•°æ®è¡¨ï¼š")
        logger.warning("   â€¢ disease_records (ç–¾ç—…è®°å½•)")
        logger.warning("   â€¢ diseases (ç–¾ç—…)")
        logger.warning("   â€¢ disease_mappings (ç–¾ç—…æ˜ å°„)")
        logger.warning("   â€¢ standard_diseases (æ ‡å‡†ç–¾ç—…åº“)")
        
        logger.info("\nğŸ“Š å½“å‰æ•°æ®ç»Ÿè®¡ï¼š")
        
        tables = {
            "disease_records": "ç–¾ç—…è®°å½•",
            "diseases": "ç–¾ç—…",
            "disease_mappings": "ç–¾ç—…æ˜ å°„",
            "standard_diseases": "æ ‡å‡†ç–¾ç—…"
        }
        
        for table, name in tables.items():
            try:
                result = await db.execute(text(f"SELECT COUNT(*) FROM {table}"))
                count = result.scalar()
                logger.info(f"   â€¢ {name:12s}: {count:,} æ¡")
            except Exception:
                logger.info(f"   â€¢ {name:12s}: (è¡¨ä¸å­˜åœ¨)")
        
        logger.info("\nğŸ“¥ å°†è¦å¯¼å…¥ï¼š")
        logger.info(f"   â€¢ æ ‡å‡†ç–¾ç—…åº“: {self.standard_file.name}")
        logger.info(f"   â€¢ ç–¾ç—…æ˜ å°„: {self.mapping_file.name}")
        logger.info(f"   â€¢ å†å²æ•°æ®: {self.history_file.name}")
        
    def _confirm_rebuild(self):
        """è¯¢é—®ç”¨æˆ·ç¡®è®¤"""
        logger.info("\n" + "=" * 80)
        try:
            response = input("ğŸ”” ç¡®è®¤è¦ç»§ç»­å—ï¼Ÿæ‰€æœ‰ç°æœ‰æ•°æ®å°†è¢«åˆ é™¤ï¼(yes/no): ")
            return response.lower() in ('yes', 'y')
        except (KeyboardInterrupt, EOFError):
            print()  # æ–°è¡Œ
            return False
    
    async def clear_data(self, db):
        """æ¸…ç©ºæ‰€æœ‰ç–¾ç—…ç›¸å…³æ•°æ®"""
        logger.info("\nğŸ“¦ æ­¥éª¤ 1/6: æ¸…ç©ºç°æœ‰æ•°æ®...")
        
        # æŒ‰ç…§å¤–é”®ä¾èµ–é¡ºåºåˆ é™¤
        tables = [
            "disease_records",
            "diseases", 
            "disease_mappings",
            "standard_diseases"
        ]
        
        for table in tables:
            result = await db.execute(text(f"SELECT COUNT(*) FROM {table}"))
            count = result.scalar()
            
            await db.execute(text(f"DELETE FROM {table}"))
            logger.info(f"  âœ“ æ¸…ç©º {table}: åˆ é™¤ {count} æ¡è®°å½•")
        
        await db.commit()
        logger.info("âœ“ æ•°æ®æ¸…ç©ºå®Œæˆ")
    
    async def import_standard_diseases(self, db):
        """å¯¼å…¥æ ‡å‡†ç–¾ç—…åº“"""
        logger.info("\nğŸ“š æ­¥éª¤ 2/6: å¯¼å…¥æ ‡å‡†ç–¾ç—…åº“...")
        
        if not self.standard_file.exists():
            raise FileNotFoundError(f"æ ‡å‡†ç–¾ç—…æ–‡ä»¶ä¸å­˜åœ¨: {self.standard_file}")
        
        df = pd.read_csv(self.standard_file).fillna('')
        logger.info(f"  è¯»å– {len(df)} æ¡æ ‡å‡†ç–¾ç—…")
        
        # è°ƒæ•´ category åˆ—å…è®¸ NULL
        await db.execute(text("""
            ALTER TABLE standard_diseases 
            ALTER COLUMN category DROP NOT NULL
        """))
        
        inserted = 0
        for _, row in df.iterrows():
            await db.execute(text("""
                INSERT INTO standard_diseases 
                (disease_id, standard_name_en, standard_name_zh, category, icd_10, icd_11, 
                 description, source, is_active)
                VALUES 
                (:disease_id, :name_en, :name_zh, :category, :icd_10, :icd_11, 
                 :description, :source, true)
                ON CONFLICT (disease_id) DO UPDATE SET
                    standard_name_en = EXCLUDED.standard_name_en,
                    standard_name_zh = EXCLUDED.standard_name_zh,
                    category = EXCLUDED.category,
                    icd_10 = EXCLUDED.icd_10,
                    icd_11 = EXCLUDED.icd_11,
                    description = EXCLUDED.description,
                    source = EXCLUDED.source,
                    updated_at = CURRENT_TIMESTAMP
            """), {
                'disease_id': row['disease_id'],
                'name_en': row['standard_name_en'],
                'name_zh': row['standard_name_zh'],
                'category': row['category'] if row['category'] else None,
                'icd_10': row.get('icd_10', ''),
                'icd_11': row.get('icd_11', ''),
                'description': row.get('description', ''),
                'source': row.get('source', 'Manual')
            })
            inserted += 1
        
        await db.commit()
        logger.info(f"âœ“ å¯¼å…¥ {inserted} æ¡æ ‡å‡†ç–¾ç—…")
    
    async def import_disease_mappings(self, db):
        """å¯¼å…¥ç–¾ç—…æ˜ å°„å…³ç³»"""
        logger.info("\nğŸ—ºï¸  æ­¥éª¤ 3/6: å¯¼å…¥ç–¾ç—…æ˜ å°„...")
        
        if not self.mapping_file.exists():
            raise FileNotFoundError(f"æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {self.mapping_file}")
        
        df = pd.read_csv(self.mapping_file).fillna('')
        logger.info(f"  è¯»å– {len(df)} æ¡æ˜ å°„å…³ç³»")
        
        # è°ƒæ•´ category åˆ—å…è®¸ NULL
        await db.execute(text("""
            ALTER TABLE disease_mappings 
            ALTER COLUMN category DROP NOT NULL
        """))
        
        inserted = 0
        for _, row in df.iterrows():
            disease_id = row['disease_id']
            local_name = row['local_name']
            
            # ä¸»è¦åç§°
            await db.execute(text("""
                INSERT INTO disease_mappings 
                (disease_id, country_code, local_name, is_primary, is_alias, priority, 
                 category, source, is_active)
                VALUES 
                (:disease_id, :country, :local_name, true, false, 100, 
                 :category, :source, true)
                ON CONFLICT (disease_id, country_code, local_name) DO UPDATE SET
                    is_primary = true,
                    category = EXCLUDED.category,
                    source = EXCLUDED.source,
                    updated_at = CURRENT_TIMESTAMP
            """), {
                'disease_id': disease_id,
                'country': self.country_code,
                'local_name': local_name,
                'category': row['category'] if row['category'] else None,
                'source': row.get('data_source', row.get('source', 'Manual'))
            })
            inserted += 1
            
            # åˆ«å
            if row.get('aliases'):
                aliases = [a.strip() for a in str(row['aliases']).split(',') if a.strip()]
                for alias in aliases:
                    await db.execute(text("""
                        INSERT INTO disease_mappings 
                        (disease_id, country_code, local_name, is_primary, is_alias, priority,
                         category, source, is_active)
                        VALUES 
                        (:disease_id, :country, :alias, false, true, 50,
                         :category, :source, true)
                        ON CONFLICT (disease_id, country_code, local_name) DO UPDATE SET
                            is_alias = true,
                            updated_at = CURRENT_TIMESTAMP
                    """), {
                        'disease_id': disease_id,
                        'country': self.country_code,
                        'alias': alias,
                        'category': row['category'] if row['category'] else None,
                        'source': row.get('source', 'Manual')
                    })
                    inserted += 1
        
        await db.commit()
        logger.info(f"âœ“ å¯¼å…¥ {inserted} æ¡æ˜ å°„å…³ç³»")
    
    async def sync_diseases_table(self, db):
        """åŒæ­¥ diseases è¡¨"""
        logger.info("\nğŸ”„ æ­¥éª¤ 4/6: åŒæ­¥ diseases è¡¨...")
        
        # ä» standard_diseases å¯¼å…¥åˆ° diseases
        result = await db.execute(text("""
            INSERT INTO diseases (name, name_en, category, icd_10, icd_11, description, 
                                aliases, keywords, metadata, is_active, created_at, updated_at)
            SELECT 
                disease_id,
                standard_name_en,
                COALESCE(category, 'Other'),
                icd_10,
                icd_11,
                description,
                '[]'::json,
                '[]'::json,
                '{}'::json,
                is_active,
                CURRENT_TIMESTAMP,
                CURRENT_TIMESTAMP
            FROM standard_diseases
            ON CONFLICT (name) DO UPDATE SET
                name_en = EXCLUDED.name_en,
                category = EXCLUDED.category,
                icd_10 = EXCLUDED.icd_10,
                icd_11 = EXCLUDED.icd_11,
                description = EXCLUDED.description,
                updated_at = CURRENT_TIMESTAMP
            RETURNING id
        """))
        
        count = len(result.fetchall())
        await db.commit()
        logger.info(f"âœ“ åŒæ­¥ {count} æ¡ç–¾ç—…åˆ° diseases è¡¨")
    
    async def import_history_data(self, db):
        """å¯¼å…¥å†å²æ•°æ®ï¼ˆåŒ…å«å®Œæ•´å­—æ®µï¼šdata_source, incidence_rate, metadataç­‰ï¼‰"""
        logger.info("\nğŸ“Š æ­¥éª¤ 5/6: å¯¼å…¥å†å²æ•°æ®...")
        
        if not self.history_file.exists():
            logger.warning(f"å†å²æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.history_file}")
            return
        
        # è¯»å–å†å²æ•°æ®
        df = pd.read_csv(self.history_file)
        logger.info(f"  è¯»å– {len(df)} æ¡å†å²è®°å½•")
        
        # è·å–ä¸­å›½çš„ country_id
        result = await db.execute(text("SELECT id FROM countries WHERE code = 'CN'"))
        country_row = result.fetchone()
        if not country_row:
            logger.error("æœªæ‰¾åˆ°ä¸­å›½çš„ country_id")
            return
        country_id = country_row[0]
        
        # æ„å»ºæ˜ å°„å­—å…¸ï¼ˆæ”¯æŒå½’ä¸€åŒ–åŒ¹é…ï¼‰
        result = await db.execute(text("""
            SELECT dm.local_name, d.id
            FROM disease_mappings dm
            JOIN diseases d ON dm.disease_id = d.name
            WHERE dm.country_code = 'CN' AND dm.is_active = true
        """))
        
        # ä½¿ç”¨å½’ä¸€åŒ–é”®æé«˜åŒ¹é…å®¹é”™æ€§
        def _norm(s):
            try:
                return s.strip().lower()
            except Exception:
                return None
        
        mapping_dict = {}
        for row in result:
            local_name = row[0]
            db_id = row[1]
            normalized = _norm(local_name)
            if normalized:
                mapping_dict[normalized] = db_id
        
        logger.info(f"  åŠ è½½ {len(mapping_dict)} ä¸ªç–¾ç—…æ˜ å°„ï¼ˆå½’ä¸€åŒ–ï¼‰")
        
        # ç¡®å®šåˆ—å
        date_col = self._find_column(df, ['Date', 'date', 'time', 'Time', 'YearMonthDay'])
        disease_cn_col = self._find_column(df, ['DiseasesCN', 'disease_cn', 'ç–¾ç—…åç§°', 'ç—…å'])
        disease_en_col = self._find_column(df, ['Diseases', 'disease_en', 'Disease'])
        cases_col = self._find_column(df, ['Cases', 'cases', 'case', 'å‘ç—…æ•°'])
        deaths_col = self._find_column(df, ['Deaths', 'deaths', 'death', 'æ­»äº¡æ•°'])
        
        if not all([date_col, disease_cn_col, cases_col, deaths_col]):
            logger.error("CSV ç¼ºå°‘å¿…è¦åˆ—")
            return
        
        # æ‰¹é‡å¯¼å…¥æ•°æ®ï¼ˆåŒ…å«å®Œæ•´å­—æ®µï¼‰
        inserted = 0
        skipped = 0
        batch_size = 1000
        batch_data = []
        
        for idx, row in df.iterrows():
            try:
                # æå–åŸºæœ¬å­—æ®µ
                disease_cn = str(row[disease_cn_col]) if pd.notna(row[disease_cn_col]) else None
                if not disease_cn or disease_cn == 'nan':
                    skipped += 1
                    continue
                
                disease_en = str(row[disease_en_col]) if disease_en_col and pd.notna(row[disease_en_col]) else None
                
                # æŸ¥æ‰¾æ˜ å°„ï¼ˆä½¿ç”¨å½’ä¸€åŒ–ï¼‰
                db_disease_id = None
                if disease_en:
                    db_disease_id = mapping_dict.get(_norm(disease_en))
                if not db_disease_id:
                    db_disease_id = mapping_dict.get(_norm(disease_cn))
                
                if not db_disease_id:
                    skipped += 1
                    continue
                
                # è§£ææ—¥æœŸ
                date_str = str(row[date_col])
                try:
                    if '/' in date_str:
                        date_obj = datetime.strptime(date_str, '%Y/%m/%d')
                    else:
                        date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                except:
                    skipped += 1
                    continue
                
                # æå–æ•°å€¼
                cases = int(row[cases_col]) if pd.notna(row[cases_col]) and str(row[cases_col]) not in ['', '-10', 'nan'] else 0
                deaths = int(row[deaths_col]) if pd.notna(row[deaths_col]) and str(row[deaths_col]) not in ['', '-10', 'nan'] else 0
                
                # æå–é¢å¤–å­—æ®µ
                incidence = None
                if 'Incidence' in df.columns and pd.notna(row['Incidence']):
                    val = float(row['Incidence'])
                    incidence = val if val >= 0 else None
                
                mortality = None
                if 'Mortality' in df.columns and pd.notna(row['Mortality']):
                    val = float(row['Mortality'])
                    mortality = val if val >= 0 else None
                
                region = None
                if 'ProvinceCN' in df.columns and pd.notna(row['ProvinceCN']) and str(row['ProvinceCN']) != 'å…¨å›½':
                    region = str(row['ProvinceCN'])
                elif 'Province' in df.columns and pd.notna(row['Province']) and str(row['Province']) != 'China':
                    region = str(row['Province'])
                
                # çœŸå®çš„æ•°æ®æ¥æº
                data_source = 'Historical Data Import'
                if 'Source' in df.columns and pd.notna(row['Source']):
                    data_source = str(row['Source'])
                
                # æ„å»º metadata
                metadata_obj = {
                    'source_csv': self.history_file.name,
                    'row_index': int(idx)
                }
                
                if '__source_file' in df.columns and pd.notna(row.get('__source_file')):
                    metadata_obj['source_file'] = str(row['__source_file'])
                if 'DOI' in df.columns and pd.notna(row['DOI']):
                    metadata_obj['doi'] = str(row['DOI'])
                if 'URL' in df.columns and pd.notna(row['URL']):
                    metadata_obj['url'] = str(row['URL'])
                if 'ADCode' in df.columns and pd.notna(row['ADCode']):
                    metadata_obj['adcode'] = str(int(row['ADCode']))
                
                batch_data.append({
                    'time': date_obj,
                    'disease_id': db_disease_id,
                    'country_id': country_id,
                    'cases': max(0, cases),
                    'deaths': max(0, deaths),
                    'incidence_rate': incidence,
                    'mortality_rate': mortality,
                    'region': region,
                    'data_source': data_source,
                    'metadata': json.dumps(metadata_obj)
                })
                
                # æ‰¹é‡æ’å…¥
                if len(batch_data) >= batch_size:
                    inserted += await self._batch_insert_enhanced(db, batch_data)
                    batch_data = []
                    
                    if inserted % 5000 == 0:
                        logger.info(f"  å·²å¯¼å…¥ {inserted} æ¡è®°å½•...")
                        
            except Exception as e:
                skipped += 1
                continue
        
        # æ’å…¥å‰©ä½™æ•°æ®
        if batch_data:
            inserted += await self._batch_insert_enhanced(db, batch_data)
        
        await db.commit()
        logger.info(f"âœ“ å¯¼å…¥ {inserted} æ¡å†å²è®°å½• (è·³è¿‡ {skipped} æ¡)")
    
    async def _batch_insert(self, db, batch_data):
        """æ‰¹é‡æ’å…¥æ•°æ®"""
        if not batch_data:
            return 0
        
        try:
            # ä½¿ç”¨ executemany æ‰¹é‡æ’å…¥
            await db.execute(text("""
                INSERT INTO disease_records 
                (time, disease_id, country_id, cases, deaths, new_cases, new_deaths,
                 recoveries, active_cases, new_recoveries, metadata)
                VALUES 
                (:time, :disease_id, :country_id, :cases, :deaths, 0, 0, 0, 0, 0, :metadata)
                ON CONFLICT (time, disease_id, country_id) DO UPDATE SET
                    cases = EXCLUDED.cases, 
                    deaths = EXCLUDED.deaths
            """), batch_data)
            return len(batch_data)
        except Exception as e:
            logger.warning(f"æ‰¹é‡æ’å…¥å¤±è´¥ï¼Œå°è¯•å•æ¡æ’å…¥: {str(e)[:200]}")
            # å›æ»šå½“å‰äº‹åŠ¡
            await db.rollback()
            # å›é€€åˆ°å•æ¡æ’å…¥
            success = 0
            for data in batch_data:
                try:
                    await db.execute(text("""
                        INSERT INTO disease_records 
                        (time, disease_id, country_id, cases, deaths, new_cases, new_deaths,
                         recoveries, active_cases, new_recoveries, metadata)
                        VALUES 
                        (:time, :disease_id, :country_id, :cases, :deaths, 0, 0, 0, 0, 0, :metadata)
                        ON CONFLICT (time, disease_id, country_id) DO UPDATE SET
                            cases = EXCLUDED.cases, deaths = EXCLUDED.deaths
                    """), data)
                    success += 1
                except Exception as inner_e:
                    await db.rollback()
                    continue
            return success
    
    async def _batch_insert_enhanced(self, db, batch_data):
        """æ‰¹é‡æ’å…¥æ•°æ®ï¼ˆåŒ…å«å®Œæ•´å­—æ®µï¼‰"""
        if not batch_data:
            return 0
        
        try:
            # ä½¿ç”¨ executemany æ‰¹é‡æ’å…¥ï¼ˆåŒ…å«æ‰€æœ‰å­—æ®µï¼‰
            await db.execute(text("""
                INSERT INTO disease_records 
                (time, disease_id, country_id, cases, deaths, 
                 incidence_rate, mortality_rate, region, data_source,
                 new_cases, new_deaths, recoveries, active_cases, new_recoveries, 
                 metadata)
                VALUES 
                (:time, :disease_id, :country_id, :cases, :deaths, 
                 :incidence_rate, :mortality_rate, :region, :data_source,
                 0, 0, 0, 0, 0, :metadata)
                ON CONFLICT (time, disease_id, country_id) DO UPDATE SET
                    cases = EXCLUDED.cases, 
                    deaths = EXCLUDED.deaths,
                    incidence_rate = EXCLUDED.incidence_rate,
                    mortality_rate = EXCLUDED.mortality_rate,
                    region = EXCLUDED.region,
                    data_source = EXCLUDED.data_source,
                    metadata = EXCLUDED.metadata
            """), batch_data)
            return len(batch_data)
        except Exception as e:
            logger.warning(f"æ‰¹é‡æ’å…¥å¤±è´¥ï¼Œå°è¯•å•æ¡æ’å…¥: {str(e)[:200]}")
            # å›æ»šå½“å‰äº‹åŠ¡
            await db.rollback()
            # å›é€€åˆ°å•æ¡æ’å…¥
            success = 0
            for data in batch_data:
                try:
                    await db.execute(text("""
                        INSERT INTO disease_records 
                        (time, disease_id, country_id, cases, deaths, 
                         incidence_rate, mortality_rate, region, data_source,
                         new_cases, new_deaths, recoveries, active_cases, new_recoveries, 
                         metadata)
                        VALUES 
                        (:time, :disease_id, :country_id, :cases, :deaths, 
                         :incidence_rate, :mortality_rate, :region, :data_source,
                         0, 0, 0, 0, 0, :metadata)
                        ON CONFLICT (time, disease_id, country_id) DO UPDATE SET
                            cases = EXCLUDED.cases, 
                            deaths = EXCLUDED.deaths,
                            incidence_rate = EXCLUDED.incidence_rate,
                            mortality_rate = EXCLUDED.mortality_rate,
                            region = EXCLUDED.region,
                            data_source = EXCLUDED.data_source,
                            metadata = EXCLUDED.metadata
                    """), data)
                    success += 1
                except Exception as inner_e:
                    await db.rollback()
                    continue
            return success
    
    def _find_column(self, df, candidates):
        """æŸ¥æ‰¾åˆ—å"""
        for col in candidates:
            if col in df.columns:
                return col
        return None
    
    async def verify_results(self, db):
        """éªŒè¯å¯¼å…¥ç»“æœ"""
        logger.info("\nâœ… æ­¥éª¤ 6/6: éªŒè¯æ•°æ®...")
        
        # æ ‡å‡†ç–¾ç—…æ•°
        result = await db.execute(text("SELECT COUNT(*) FROM standard_diseases"))
        std_count = result.scalar()
        logger.info(f"  â€¢ æ ‡å‡†ç–¾ç—…åº“: {std_count} æ¡")
        
        # æ˜ å°„å…³ç³»æ•°
        result = await db.execute(text("""
            SELECT COUNT(*), COUNT(DISTINCT disease_id) 
            FROM disease_mappings WHERE country_code = 'CN'
        """))
        map_total, map_diseases = result.fetchone()
        logger.info(f"  â€¢ ç–¾ç—…æ˜ å°„: {map_total} æ¡æ˜ å°„ï¼Œè¦†ç›– {map_diseases} ä¸ªç–¾ç—…")
        
        # diseases è¡¨
        result = await db.execute(text("SELECT COUNT(*) FROM diseases"))
        diseases_count = result.scalar()
        logger.info(f"  â€¢ Diseases è¡¨: {diseases_count} æ¡")
        
        # å†å²è®°å½•
        result = await db.execute(text("""
            SELECT 
                COUNT(*) as total,
                COUNT(DISTINCT disease_id) as diseases,
                MIN(time) as earliest,
                MAX(time) as latest
            FROM disease_records
        """))
        rec = result.fetchone()
        logger.info(f"  â€¢ å†å²è®°å½•: {rec[0]} æ¡")
        logger.info(f"  â€¢ è¦†ç›–ç–¾ç—…: {rec[1]} ä¸ª")
        logger.info(f"  â€¢ æ—¶é—´èŒƒå›´: {rec[2]} è‡³ {rec[3]}")
        
        # ç—¢ç–¾æ•°æ®éªŒè¯
        result = await db.execute(text("""
            SELECT d.name, sd.standard_name_zh, COUNT(*) as cnt
            FROM disease_records r
            JOIN diseases d ON r.disease_id = d.id
            LEFT JOIN standard_diseases sd ON d.name = sd.disease_id
            WHERE d.name = 'D024'
            GROUP BY d.name, sd.standard_name_zh
        """))
        dysentery = result.fetchone()
        if dysentery:
            logger.info(f"\n  ğŸ¯ ç—¢ç–¾æ•°æ®: {dysentery[1]} ({dysentery[0]}) - {dysentery[2]} æ¡è®°å½•")


async def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description='å®Œæ•´é‡å»ºæ•°æ®åº“ï¼ˆæ¸…ç©ºç°æœ‰æ•°æ®å¹¶é‡æ–°å¯¼å…¥ï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  # äº¤äº’å¼è¿è¡Œï¼ˆä¼šè¯¢é—®ç¡®è®¤ï¼‰
  python scripts/full_rebuild_database.py
  
  # è‡ªåŠ¨ç¡®è®¤ï¼ˆè·³è¿‡è¯¢é—®ï¼‰
  python scripts/full_rebuild_database.py --yes
  
æ³¨æ„ï¼šæ­¤æ“ä½œä¼šæ¸…ç©ºæ‰€æœ‰ç–¾ç—…ç›¸å…³æ•°æ®ï¼Œè¯·è°¨æ…ä½¿ç”¨ï¼
        """
    )
    parser.add_argument(
        '--yes', '-y',
        action='store_true',
        help='è‡ªåŠ¨ç¡®è®¤ï¼Œè·³è¿‡è¯¢é—®ï¼ˆç”¨äºè‡ªåŠ¨åŒ–è„šæœ¬ï¼‰'
    )
    
    args = parser.parse_args()
    
    try:
        rebuilder = DatabaseRebuilder(auto_confirm=args.yes)
        await rebuilder.run()
    except Exception as e:
        logger.error(f"âŒ é‡å»ºå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
