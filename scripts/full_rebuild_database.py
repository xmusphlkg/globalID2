#!/usr/bin/env python3
"""
å®Œæ•´é‡å»ºæ•°æ®åº“ - ä¸€ä½“å¼è„šæœ¬

åŠŸèƒ½ï¼š
1. æ¸…ç©ºæ‰€æœ‰ç–¾ç—…ç›¸å…³è¡¨
2. ä» CSV å¯¼å…¥æ ‡å‡†ç–¾ç—…åº“å’Œæ˜ å°„å…³ç³»
3. åŒæ­¥ diseases è¡¨
4. å¯¼å…¥å†å²æ•°æ®åˆ° disease_records
5. éªŒè¯æ•°æ®å®Œæ•´æ€§

ä¸€æ¬¡è¿è¡Œï¼Œå…¨éƒ¨å®Œæˆï¼
"""
import asyncio
import sys
from pathlib import Path
from datetime import datetime
import pandas as pd
from typing import Dict, Set

ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(ROOT))

from sqlalchemy import text
from src.core.database import get_db
from src.core.logging import get_logger

logger = get_logger(__name__)


class DatabaseRebuilder:
    def __init__(self):
        self.standard_file = ROOT / "configs/standard_diseases.csv"
        self.mapping_file = ROOT / "configs/cn/disease_mapping.csv"
        self.history_file = ROOT / "data/processed/history_merged.csv"
        self.country_code = "CN"
        
    async def run(self):
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®åº“é‡å»ºæµç¨‹"""
        logger.info("=" * 80)
        logger.info("ğŸš€ å¼€å§‹å®Œæ•´æ•°æ®åº“é‡å»ºæµç¨‹")
        logger.info("=" * 80)
        
        async with get_db() as db:
            # æ­¥éª¤ 1: æ¸…ç©ºæ•°æ®
            await self.clear_data(db)
            
            # æ­¥éª¤ 2: å¯¼å…¥æ ‡å‡†ç–¾ç—…åº“
            await self.import_standard_diseases(db)
            
            # æ­¥éª¤ 3: å¯¼å…¥ç–¾ç—…æ˜ å°„
            await self.import_disease_mappings(db)
            
            # æ­¥éª¤ 4: åŒæ­¥ diseases è¡¨
            await self.sync_diseases_table(db)
            
            # æ­¥éª¤ 5: å¯¼å…¥å†å²æ•°æ®
            await self.import_history_data(db)
            
            # æ­¥éª¤ 6: éªŒè¯ç»“æœ
            await self.verify_results(db)
            
        logger.info("\n" + "=" * 80)
        logger.info("âœ… æ•°æ®åº“é‡å»ºå®Œæˆï¼")
        logger.info("=" * 80)
    
    async def clear_data(self, db):
        """æ¸…ç©ºæ‰€æœ‰ç–¾ç—…ç›¸å…³æ•°æ®"""
        logger.info("\nğŸ“¦ æ­¥éª¤ 1/6: æ¸…ç©ºç°æœ‰æ•°æ®...")
        
        # æŒ‰ç…§å¤–é”®ä¾èµ–é¡ºåºåˆ é™¤
        tables = [
            "disease_records",
            "diseases", 
            "disease_mappings",
            "standard_diseases"
        ]
        
        for table in tables:
            result = await db.execute(text(f"SELECT COUNT(*) FROM {table}"))
            count = result.scalar()
            
            await db.execute(text(f"DELETE FROM {table}"))
            logger.info(f"  âœ“ æ¸…ç©º {table}: åˆ é™¤ {count} æ¡è®°å½•")
        
        await db.commit()
        logger.info("âœ“ æ•°æ®æ¸…ç©ºå®Œæˆ")
    
    async def import_standard_diseases(self, db):
        """å¯¼å…¥æ ‡å‡†ç–¾ç—…åº“"""
        logger.info("\nğŸ“š æ­¥éª¤ 2/6: å¯¼å…¥æ ‡å‡†ç–¾ç—…åº“...")
        
        if not self.standard_file.exists():
            raise FileNotFoundError(f"æ ‡å‡†ç–¾ç—…æ–‡ä»¶ä¸å­˜åœ¨: {self.standard_file}")
        
        df = pd.read_csv(self.standard_file).fillna('')
        logger.info(f"  è¯»å– {len(df)} æ¡æ ‡å‡†ç–¾ç—…")
        
        # è°ƒæ•´ category åˆ—å…è®¸ NULL
        await db.execute(text("""
            ALTER TABLE standard_diseases 
            ALTER COLUMN category DROP NOT NULL
        """))
        
        inserted = 0
        for _, row in df.iterrows():
            await db.execute(text("""
                INSERT INTO standard_diseases 
                (disease_id, standard_name_en, standard_name_zh, category, icd_10, icd_11, 
                 description, source, is_active)
                VALUES 
                (:disease_id, :name_en, :name_zh, :category, :icd_10, :icd_11, 
                 :description, :source, true)
                ON CONFLICT (disease_id) DO UPDATE SET
                    standard_name_en = EXCLUDED.standard_name_en,
                    standard_name_zh = EXCLUDED.standard_name_zh,
                    category = EXCLUDED.category,
                    icd_10 = EXCLUDED.icd_10,
                    icd_11 = EXCLUDED.icd_11,
                    description = EXCLUDED.description,
                    source = EXCLUDED.source,
                    updated_at = CURRENT_TIMESTAMP
            """), {
                'disease_id': row['disease_id'],
                'name_en': row['standard_name_en'],
                'name_zh': row['standard_name_zh'],
                'category': row['category'] if row['category'] else None,
                'icd_10': row.get('icd_10', ''),
                'icd_11': row.get('icd_11', ''),
                'description': row.get('description', ''),
                'source': row.get('source', 'Manual')
            })
            inserted += 1
        
        await db.commit()
        logger.info(f"âœ“ å¯¼å…¥ {inserted} æ¡æ ‡å‡†ç–¾ç—…")
    
    async def import_disease_mappings(self, db):
        """å¯¼å…¥ç–¾ç—…æ˜ å°„å…³ç³»"""
        logger.info("\nğŸ—ºï¸  æ­¥éª¤ 3/6: å¯¼å…¥ç–¾ç—…æ˜ å°„...")
        
        if not self.mapping_file.exists():
            raise FileNotFoundError(f"æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {self.mapping_file}")
        
        df = pd.read_csv(self.mapping_file).fillna('')
        logger.info(f"  è¯»å– {len(df)} æ¡æ˜ å°„å…³ç³»")
        
        # è°ƒæ•´ category åˆ—å…è®¸ NULL
        await db.execute(text("""
            ALTER TABLE disease_mappings 
            ALTER COLUMN category DROP NOT NULL
        """))
        
        inserted = 0
        for _, row in df.iterrows():
            disease_id = row['disease_id']
            local_name = row['local_name']
            
            # ä¸»è¦åç§°
            await db.execute(text("""
                INSERT INTO disease_mappings 
                (disease_id, country_code, local_name, is_primary, is_alias, priority, 
                 category, source, is_active)
                VALUES 
                (:disease_id, :country, :local_name, true, false, 100, 
                 :category, :source, true)
                ON CONFLICT (disease_id, country_code, local_name) DO UPDATE SET
                    is_primary = true,
                    category = EXCLUDED.category,
                    source = EXCLUDED.source,
                    updated_at = CURRENT_TIMESTAMP
            """), {
                'disease_id': disease_id,
                'country': self.country_code,
                'local_name': local_name,
                'category': row['category'] if row['category'] else None,
                'source': row.get('data_source', row.get('source', 'Manual'))
            })
            inserted += 1
            
            # åˆ«å
            if row.get('aliases'):
                aliases = [a.strip() for a in str(row['aliases']).split(',') if a.strip()]
                for alias in aliases:
                    await db.execute(text("""
                        INSERT INTO disease_mappings 
                        (disease_id, country_code, local_name, is_primary, is_alias, priority,
                         category, source, is_active)
                        VALUES 
                        (:disease_id, :country, :alias, false, true, 50,
                         :category, :source, true)
                        ON CONFLICT (disease_id, country_code, local_name) DO UPDATE SET
                            is_alias = true,
                            updated_at = CURRENT_TIMESTAMP
                    """), {
                        'disease_id': disease_id,
                        'country': self.country_code,
                        'alias': alias,
                        'category': row['category'] if row['category'] else None,
                        'source': row.get('source', 'Manual')
                    })
                    inserted += 1
        
        await db.commit()
        logger.info(f"âœ“ å¯¼å…¥ {inserted} æ¡æ˜ å°„å…³ç³»")
    
    async def sync_diseases_table(self, db):
        """åŒæ­¥ diseases è¡¨"""
        logger.info("\nğŸ”„ æ­¥éª¤ 4/6: åŒæ­¥ diseases è¡¨...")
        
        # ä» standard_diseases å¯¼å…¥åˆ° diseases
        result = await db.execute(text("""
            INSERT INTO diseases (name, name_en, category, icd_10, icd_11, description, 
                                aliases, keywords, metadata, is_active, created_at, updated_at)
            SELECT 
                disease_id,
                standard_name_en,
                COALESCE(category, 'Other'),
                icd_10,
                icd_11,
                description,
                '[]'::json,
                '[]'::json,
                '{}'::json,
                is_active,
                CURRENT_TIMESTAMP,
                CURRENT_TIMESTAMP
            FROM standard_diseases
            ON CONFLICT (name) DO UPDATE SET
                name_en = EXCLUDED.name_en,
                category = EXCLUDED.category,
                icd_10 = EXCLUDED.icd_10,
                icd_11 = EXCLUDED.icd_11,
                description = EXCLUDED.description,
                updated_at = CURRENT_TIMESTAMP
            RETURNING id
        """))
        
        count = len(result.fetchall())
        await db.commit()
        logger.info(f"âœ“ åŒæ­¥ {count} æ¡ç–¾ç—…åˆ° diseases è¡¨")
    
    async def import_history_data(self, db):
        """å¯¼å…¥å†å²æ•°æ®"""
        logger.info("\nğŸ“Š æ­¥éª¤ 5/6: å¯¼å…¥å†å²æ•°æ®...")
        
        if not self.history_file.exists():
            logger.warning(f"å†å²æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.history_file}")
            return
        
        # è¯»å–å†å²æ•°æ®
        df = pd.read_csv(self.history_file)
        logger.info(f"  è¯»å– {len(df)} æ¡å†å²è®°å½•")
        
        # è·å–ä¸­å›½çš„ country_id
        result = await db.execute(text("SELECT id FROM countries WHERE code = 'CN'"))
        country_row = result.fetchone()
        if not country_row:
            logger.error("æœªæ‰¾åˆ°ä¸­å›½çš„ country_id")
            return
        country_id = country_row[0]
        
        # æ„å»ºæ˜ å°„å­—å…¸
        result = await db.execute(text("""
            SELECT dm.local_name, d.id
            FROM disease_mappings dm
            JOIN diseases d ON dm.disease_id = d.name
            WHERE dm.country_code = 'CN' AND dm.is_active = true
        """))
        mapping_dict = {row[0]: row[1] for row in result}
        logger.info(f"  åŠ è½½ {len(mapping_dict)} ä¸ªç–¾ç—…æ˜ å°„")
        
        # ç¡®å®šåˆ—å
        date_col = self._find_column(df, ['Date', 'date', 'time', 'Time', 'YearMonthDay'])
        disease_cn_col = self._find_column(df, ['DiseasesCN', 'disease_cn', 'ç–¾ç—…åç§°', 'ç—…å'])
        disease_en_col = self._find_column(df, ['Diseases', 'disease_en', 'Disease'])
        cases_col = self._find_column(df, ['Cases', 'cases', 'case', 'å‘ç—…æ•°'])
        deaths_col = self._find_column(df, ['Deaths', 'deaths', 'death', 'æ­»äº¡æ•°'])
        
        if not all([date_col, disease_cn_col, cases_col, deaths_col]):
            logger.error("CSV ç¼ºå°‘å¿…è¦åˆ—")
            return
        
        # æ‰¹é‡å¯¼å…¥æ•°æ®
        inserted = 0
        skipped = 0
        batch_size = 1000
        batch_data = []
        
        for idx, row in df.iterrows():
            try:
                disease_cn = str(row[disease_cn_col]) if pd.notna(row[disease_cn_col]) else None
                if not disease_cn or disease_cn == 'nan':
                    skipped += 1
                    continue
                
                # æŸ¥æ‰¾æ˜ å°„
                db_disease_id = mapping_dict.get(disease_cn)
                if not db_disease_id and disease_en_col:
                    disease_en = str(row[disease_en_col]) if pd.notna(row[disease_en_col]) else None
                    if disease_en:
                        db_disease_id = mapping_dict.get(disease_en)
                
                if not db_disease_id:
                    skipped += 1
                    continue
                
                # è§£ææ—¥æœŸ
                date_str = str(row[date_col])
                try:
                    if '/' in date_str:
                        date_obj = datetime.strptime(date_str, '%Y/%m/%d')
                    else:
                        date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                except:
                    skipped += 1
                    continue
                
                # æå–æ•°å€¼
                cases = int(row[cases_col]) if pd.notna(row[cases_col]) and str(row[cases_col]) not in ['', '-10', 'nan'] else 0
                deaths = int(row[deaths_col]) if pd.notna(row[deaths_col]) and str(row[deaths_col]) not in ['', '-10', 'nan'] else 0
                
                batch_data.append({
                    'time': date_obj,
                    'disease_id': db_disease_id,
                    'country_id': country_id,
                    'cases': max(0, cases),
                    'deaths': max(0, deaths),
                    'metadata': '{}'
                })
                
                # æ‰¹é‡æ’å…¥
                if len(batch_data) >= batch_size:
                    inserted += await self._batch_insert(db, batch_data)
                    batch_data = []
                    
                    if inserted % 5000 == 0:
                        logger.info(f"  å·²å¯¼å…¥ {inserted} æ¡è®°å½•...")
                        
            except Exception as e:
                skipped += 1
                continue
        
        # æ’å…¥å‰©ä½™æ•°æ®
        if batch_data:
            inserted += await self._batch_insert(db, batch_data)
        
        await db.commit()
        logger.info(f"âœ“ å¯¼å…¥ {inserted} æ¡å†å²è®°å½• (è·³è¿‡ {skipped} æ¡)")
    
    async def _batch_insert(self, db, batch_data):
        """æ‰¹é‡æ’å…¥æ•°æ®"""
        if not batch_data:
            return 0
        
        try:
            # ä½¿ç”¨ executemany æ‰¹é‡æ’å…¥
            await db.execute(text("""
                INSERT INTO disease_records 
                (time, disease_id, country_id, cases, deaths, new_cases, new_deaths,
                 recoveries, active_cases, new_recoveries, metadata)
                VALUES 
                (:time, :disease_id, :country_id, :cases, :deaths, 0, 0, 0, 0, 0, :metadata)
                ON CONFLICT (time, disease_id, country_id) DO UPDATE SET
                    cases = EXCLUDED.cases, 
                    deaths = EXCLUDED.deaths
            """), batch_data)
            return len(batch_data)
        except Exception as e:
            logger.warning(f"æ‰¹é‡æ’å…¥å¤±è´¥ï¼Œå°è¯•å•æ¡æ’å…¥: {str(e)[:200]}")
            # å›æ»šå½“å‰äº‹åŠ¡
            await db.rollback()
            # å›é€€åˆ°å•æ¡æ’å…¥
            success = 0
            for data in batch_data:
                try:
                    await db.execute(text("""
                        INSERT INTO disease_records 
                        (time, disease_id, country_id, cases, deaths, new_cases, new_deaths,
                         recoveries, active_cases, new_recoveries, metadata)
                        VALUES 
                        (:time, :disease_id, :country_id, :cases, :deaths, 0, 0, 0, 0, 0, :metadata)
                        ON CONFLICT (time, disease_id, country_id) DO UPDATE SET
                            cases = EXCLUDED.cases, deaths = EXCLUDED.deaths
                    """), data)
                    success += 1
                except Exception as inner_e:
                    await db.rollback()
                    continue
            return success
    
    def _find_column(self, df, candidates):
        """æŸ¥æ‰¾åˆ—å"""
        for col in candidates:
            if col in df.columns:
                return col
        return None
    
    async def verify_results(self, db):
        """éªŒè¯å¯¼å…¥ç»“æœ"""
        logger.info("\nâœ… æ­¥éª¤ 6/6: éªŒè¯æ•°æ®...")
        
        # æ ‡å‡†ç–¾ç—…æ•°
        result = await db.execute(text("SELECT COUNT(*) FROM standard_diseases"))
        std_count = result.scalar()
        logger.info(f"  â€¢ æ ‡å‡†ç–¾ç—…åº“: {std_count} æ¡")
        
        # æ˜ å°„å…³ç³»æ•°
        result = await db.execute(text("""
            SELECT COUNT(*), COUNT(DISTINCT disease_id) 
            FROM disease_mappings WHERE country_code = 'CN'
        """))
        map_total, map_diseases = result.fetchone()
        logger.info(f"  â€¢ ç–¾ç—…æ˜ å°„: {map_total} æ¡æ˜ å°„ï¼Œè¦†ç›– {map_diseases} ä¸ªç–¾ç—…")
        
        # diseases è¡¨
        result = await db.execute(text("SELECT COUNT(*) FROM diseases"))
        diseases_count = result.scalar()
        logger.info(f"  â€¢ Diseases è¡¨: {diseases_count} æ¡")
        
        # å†å²è®°å½•
        result = await db.execute(text("""
            SELECT 
                COUNT(*) as total,
                COUNT(DISTINCT disease_id) as diseases,
                MIN(time) as earliest,
                MAX(time) as latest
            FROM disease_records
        """))
        rec = result.fetchone()
        logger.info(f"  â€¢ å†å²è®°å½•: {rec[0]} æ¡")
        logger.info(f"  â€¢ è¦†ç›–ç–¾ç—…: {rec[1]} ä¸ª")
        logger.info(f"  â€¢ æ—¶é—´èŒƒå›´: {rec[2]} è‡³ {rec[3]}")
        
        # ç—¢ç–¾æ•°æ®éªŒè¯
        result = await db.execute(text("""
            SELECT d.name, sd.standard_name_zh, COUNT(*) as cnt
            FROM disease_records r
            JOIN diseases d ON r.disease_id = d.id
            LEFT JOIN standard_diseases sd ON d.name = sd.disease_id
            WHERE d.name = 'D024'
            GROUP BY d.name, sd.standard_name_zh
        """))
        dysentery = result.fetchone()
        if dysentery:
            logger.info(f"\n  ğŸ¯ ç—¢ç–¾æ•°æ®: {dysentery[1]} ({dysentery[0]}) - {dysentery[2]} æ¡è®°å½•")


async def main():
    try:
        rebuilder = DatabaseRebuilder()
        await rebuilder.run()
    except Exception as e:
        logger.error(f"âŒ é‡å»ºå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
