#!/usr/bin/env python3
"""
åˆ·æ–°ç–¾ç—…æ˜ å°„æ•°æ®åº“

å®Œæ•´é‡å»ºç–¾ç—…æ ‡å‡†åº“å’Œæ˜ å°„è¡¨ï¼Œç”¨äºä¿®å¤æ•°æ®ä¸ä¸€è‡´æˆ–æ›´æ–°é…ç½®æ–‡ä»¶ååŒæ­¥æ•°æ®åº“ã€‚

åŠŸèƒ½ï¼š
1. æ¸…ç†ç°æœ‰çš„ standard_diseases å’Œ disease_mappings è¡¨
2. ä» configs/standard_diseases.csv é‡æ–°å¯¼å…¥æ ‡å‡†ç–¾ç—…åº“
3. ä» configs/{country}/disease_mapping.csv é‡æ–°å¯¼å…¥å›½å®¶æ˜ å°„
4. éªŒè¯æ•°æ®å®Œæ•´æ€§å’Œä¸€è‡´æ€§
5. ç”Ÿæˆè¯¦ç»†çš„å¯¼å…¥æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/refresh_disease_mappings.py
    python scripts/refresh_disease_mappings.py --country cn
    python scripts/refresh_disease_mappings.py --dry-run  # ä»…éªŒè¯ä¸æ‰§è¡Œ
"""
import asyncio
import sys
import argparse
from pathlib import Path
from typing import Dict, List, Set
import pandas as pd

# Add project root to sys.path
ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(ROOT))

from sqlalchemy import text
from src.core.database import get_db
from src.core.logging import get_logger

logger = get_logger(__name__)


class DiseaseRefreshService:
    """ç–¾ç—…æ˜ å°„åˆ·æ–°æœåŠ¡"""
    
    def __init__(self, country_code: str = "cn", dry_run: bool = False):
        self.country_code = country_code.upper()
        self.dry_run = dry_run
        self.stats = {
            "standard_diseases_added": 0,
            "standard_diseases_updated": 0,
            "mappings_added": 0,
            "mappings_updated": 0,
            "errors": [],
            "warnings": []
        }
        
    async def refresh_all(self, skip_confirmation: bool = False):
        """æ‰§è¡Œå®Œæ•´çš„åˆ·æ–°æµç¨‹"""
        logger.info("=" * 70)
        logger.info("ç–¾ç—…æ˜ å°„æ•°æ®åº“åˆ·æ–°å·¥å…·")
        logger.info("=" * 70)
        
        if self.dry_run:
            logger.info("ğŸ” DRY RUN æ¨¡å¼ - ä»…éªŒè¯ä¸æ‰§è¡Œå®é™…æ“ä½œ")
        
        # 1. éªŒè¯æ–‡ä»¶å­˜åœ¨
        logger.info("\nğŸ“‹ æ­¥éª¤ 1/5: éªŒè¯é…ç½®æ–‡ä»¶...")
        if not await self._validate_files():
            return False
        
        # 2. ç¡®è®¤æ“ä½œ
        if not skip_confirmation and not self.dry_run:
            logger.warning("\nâš ï¸  è­¦å‘Šï¼šæ­¤æ“ä½œå°†åˆ é™¤å¹¶é‡å»º standard_diseases å’Œ disease_mappings è¡¨ï¼")
            response = input("ç¡®è®¤ç»§ç»­? è¾“å…¥ 'YES' ç»§ç»­: ")
            if response != "YES":
                logger.info("æ“ä½œå·²å–æ¶ˆ")
                return False
        
        # 3. å¤‡ä»½ç°æœ‰æ•°æ®ï¼ˆå¯é€‰ï¼‰
        logger.info("\nğŸ’¾ æ­¥éª¤ 2/5: å¤‡ä»½ç°æœ‰æ•°æ®...")
        await self._backup_existing_data()
        
        # 4. æ¸…ç†ç°æœ‰è¡¨
        logger.info("\nğŸ—‘ï¸  æ­¥éª¤ 3/5: æ¸…ç†ç°æœ‰æ•°æ®...")
        if not self.dry_run:
            await self._clear_tables()
        else:
            logger.info("  (è·³è¿‡ - DRY RUN)")
        
        # 5. å¯¼å…¥æ ‡å‡†ç–¾ç—…åº“
        logger.info("\nğŸ“¥ æ­¥éª¤ 4/5: å¯¼å…¥æ ‡å‡†ç–¾ç—…åº“...")
        await self._import_standard_diseases()
        
        # 6. å¯¼å…¥å›½å®¶æ˜ å°„
        logger.info(f"\nğŸŒ æ­¥éª¤ 5/5: å¯¼å…¥ {self.country_code} å›½å®¶æ˜ å°„...")
        await self._import_country_mappings()
        
        # 7. éªŒè¯å®Œæ•´æ€§
        logger.info("\nâœ… éªŒè¯æ•°æ®å®Œæ•´æ€§...")
        await self._validate_integrity()
        
        # 8. ç”ŸæˆæŠ¥å‘Š
        logger.info("\n" + "=" * 70)
        self._print_summary()
        logger.info("=" * 70)
        
        return len(self.stats["errors"]) == 0
    
    async def _validate_files(self) -> bool:
        """éªŒè¯æ‰€éœ€çš„é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        standard_file = ROOT / "configs/standard_diseases.csv"
        mapping_file = ROOT / f"configs/{self.country_code.lower()}/disease_mapping.csv"
        
        issues = []
        
        if not standard_file.exists():
            issues.append(f"âŒ æ‰¾ä¸åˆ°æ ‡å‡†ç–¾ç—…åº“æ–‡ä»¶: {standard_file}")
        else:
            df = pd.read_csv(standard_file)
            logger.info(f"  âœ“ æ ‡å‡†ç–¾ç—…åº“æ–‡ä»¶: {len(df)} æ¡è®°å½•")
            
            # éªŒè¯å¿…éœ€åˆ—
            required_cols = ['disease_id', 'standard_name_en', 'standard_name_zh']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                issues.append(f"âŒ æ ‡å‡†ç–¾ç—…åº“ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
        
        if not mapping_file.exists():
            issues.append(f"âŒ æ‰¾ä¸åˆ°å›½å®¶æ˜ å°„æ–‡ä»¶: {mapping_file}")
        else:
            df = pd.read_csv(mapping_file)
            logger.info(f"  âœ“ å›½å®¶æ˜ å°„æ–‡ä»¶: {len(df)} æ¡è®°å½•")
            
            # éªŒè¯å¿…éœ€åˆ—
            required_cols = ['disease_id', 'local_name']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                issues.append(f"âŒ å›½å®¶æ˜ å°„ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
        
        if issues:
            for issue in issues:
                logger.error(issue)
            return False
        
        return True
    
    async def _backup_existing_data(self):
        """å¤‡ä»½ç°æœ‰æ•°æ®åˆ° CSV"""
        backup_dir = ROOT / "data/backups"
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        try:
            async with get_db() as db:
                # å¤‡ä»½ standard_diseases
                result = await db.execute(text("SELECT * FROM standard_diseases"))
                rows = result.fetchall()
                if rows:
                    df = pd.DataFrame(rows, columns=result.keys())
                    backup_file = backup_dir / f"standard_diseases_backup_{timestamp}.csv"
                    df.to_csv(backup_file, index=False)
                    logger.info(f"  âœ“ å¤‡ä»½æ ‡å‡†ç–¾ç—…åº“: {len(df)} æ¡è®°å½• -> {backup_file.name}")
                
                # å¤‡ä»½ disease_mappings
                result = await db.execute(text(
                    f"SELECT * FROM disease_mappings WHERE country_code = '{self.country_code}'"
                ))
                rows = result.fetchall()
                if rows:
                    df = pd.DataFrame(rows, columns=result.keys())
                    backup_file = backup_dir / f"disease_mappings_{self.country_code}_backup_{timestamp}.csv"
                    df.to_csv(backup_file, index=False)
                    logger.info(f"  âœ“ å¤‡ä»½å›½å®¶æ˜ å°„: {len(df)} æ¡è®°å½• -> {backup_file.name}")
        except Exception as e:
            logger.warning(f"  âš ï¸  å¤‡ä»½å¤±è´¥ï¼ˆå¯èƒ½è¡¨ä¸å­˜åœ¨ï¼‰: {e}")
    
    async def _clear_tables(self):
        """æ¸…ç©ºç›¸å…³è¡¨"""
        async with get_db() as db:
            # åˆ é™¤æ˜ å°„ï¼ˆæœ‰å¤–é”®ä¾èµ–ï¼‰- åŒæ—¶æ¸…ç†å¤§å°å†™å˜ä½“
            await db.execute(text(f"""
                DELETE FROM disease_mappings 
                WHERE UPPER(country_code) = '{self.country_code}'
            """))
            
            # åˆ é™¤æ ‡å‡†ç–¾ç—…
            await db.execute(text("DELETE FROM standard_diseases"))
            
            await db.commit()
            logger.info("  âœ“ å·²æ¸…ç©ºè¡¨æ•°æ®")
    
    async def _import_standard_diseases(self):
        """å¯¼å…¥æ ‡å‡†ç–¾ç—…åº“"""
        standard_file = ROOT / "configs/standard_diseases.csv"
        df = pd.read_csv(standard_file).fillna('')
        
        async with get_db() as db:
            # ç¡®ä¿è¡¨å­˜åœ¨å¹¶å…è®¸ category ä¸º NULL
            await db.execute(text("""
                CREATE TABLE IF NOT EXISTS standard_diseases (
                    id SERIAL PRIMARY KEY,
                    disease_id VARCHAR(20) UNIQUE NOT NULL,
                    standard_name_en VARCHAR(200) NOT NULL,
                    standard_name_zh VARCHAR(200),
                    category VARCHAR(50),
                    icd_10 VARCHAR(50),
                    icd_11 VARCHAR(50),
                    description TEXT,
                    source VARCHAR(100),
                    is_active BOOLEAN DEFAULT true,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            
            # å¦‚æœè¡¨å·²å­˜åœ¨ï¼Œç¡®ä¿ category åˆ—å…è®¸ NULL
            await db.execute(text("""
                ALTER TABLE standard_diseases 
                ALTER COLUMN category DROP NOT NULL
            """))
            await db.commit()
            
            # æ‰¹é‡æ’å…¥
            for idx, row in df.iterrows():
                try:
                    disease_id = str(row['disease_id']).strip()
                    standard_name_en = str(row['standard_name_en']).strip()
                    standard_name_zh = str(row.get('standard_name_zh', '')).strip()
                    category = str(row.get('category', '')).strip()
                    icd_10 = str(row.get('icd_10', '')).strip() if pd.notna(row.get('icd_10')) and row.get('icd_10') else None
                    icd_11 = str(row.get('icd_11', '')).strip() if pd.notna(row.get('icd_11')) and row.get('icd_11') else None
                    description = str(row.get('description', '')).strip() if pd.notna(row.get('description')) and row.get('description') else None
                    source = str(row.get('source', 'CSV')).strip()
                    
                    if not disease_id or not standard_name_en:
                        logger.warning(f"  âš ï¸  è·³è¿‡æ— æ•ˆè®°å½• (è¡Œ {idx+2}): disease_id æˆ– standard_name_en ä¸ºç©º")
                        continue
                    
                    if not self.dry_run:
                        await db.execute(text("""
                            INSERT INTO standard_diseases (
                                disease_id, standard_name_en, standard_name_zh,
                                category, icd_10, icd_11, description, source
                            ) VALUES (
                                :disease_id, :name_en, :name_zh,
                                :category, :icd_10, :icd_11, :description, :source
                            )
                            ON CONFLICT (disease_id) DO UPDATE SET
                                standard_name_en = EXCLUDED.standard_name_en,
                                standard_name_zh = EXCLUDED.standard_name_zh,
                                category = EXCLUDED.category,
                                icd_10 = EXCLUDED.icd_10,
                                icd_11 = EXCLUDED.icd_11,
                                description = EXCLUDED.description,
                                updated_at = CURRENT_TIMESTAMP
                        """), {
                            "disease_id": disease_id,
                            "name_en": standard_name_en,
                            "name_zh": standard_name_zh,
                            "category": category if category else None,
                            "icd_10": icd_10,
                            "icd_11": icd_11,
                            "description": description,
                            "source": source
                        })
                    
                    self.stats["standard_diseases_added"] += 1
                    
                    if (idx + 1) % 20 == 0:
                        logger.info(f"  è¿›åº¦: {idx + 1}/{len(df)}")
                
                except Exception as e:
                    error_msg = f"å¯¼å…¥æ ‡å‡†ç–¾ç—…å¤±è´¥ (è¡Œ {idx+2}): {e}"
                    logger.error(f"  âŒ {error_msg}")
                    self.stats["errors"].append(error_msg)
            
            if not self.dry_run:
                await db.commit()
            
            logger.info(f"  âœ“ å·²å¯¼å…¥ {self.stats['standard_diseases_added']} æ¡æ ‡å‡†ç–¾ç—…")
    
    async def _import_country_mappings(self):
        """å¯¼å…¥å›½å®¶æ˜ å°„"""
        mapping_file = ROOT / f"configs/{self.country_code.lower()}/disease_mapping.csv"
        df = pd.read_csv(mapping_file).fillna('')
        
        # é¦–å…ˆè·å–æ‰€æœ‰æœ‰æ•ˆçš„ disease_id
        valid_disease_ids = set()
        async with get_db() as db:
            result = await db.execute(text("SELECT disease_id FROM standard_diseases"))
            valid_disease_ids = {row[0] for row in result.fetchall()}
        
        async with get_db() as db:
            # ç¡®ä¿è¡¨å­˜åœ¨
            await db.execute(text("""
                CREATE TABLE IF NOT EXISTS disease_mappings (
                    id SERIAL PRIMARY KEY,
                    country_code VARCHAR(10) NOT NULL,
                    local_name VARCHAR(200) NOT NULL,
                    disease_id VARCHAR(20) NOT NULL,
                    local_code VARCHAR(50),
                    category VARCHAR(50),
                    priority INTEGER DEFAULT 100,
                    usage_count INTEGER DEFAULT 0,
                    is_active BOOLEAN DEFAULT true,
                    last_used_at TIMESTAMP,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(country_code, local_name, disease_id)
                )
            """))
            await db.commit()
            
            # æ‰¹é‡æ’å…¥
            for idx, row in df.iterrows():
                try:
                    disease_id = str(row['disease_id']).strip()
                    local_name = str(row['local_name']).strip()
                    local_code = str(row.get('local_code', '')).strip() if pd.notna(row.get('local_code')) and row.get('local_code') else None
                    category = str(row.get('category', '')).strip() if pd.notna(row.get('category')) and row.get('category') else None
                    
                    if not disease_id or not local_name:
                        logger.warning(f"  âš ï¸  è·³è¿‡æ— æ•ˆè®°å½• (è¡Œ {idx+2}): disease_id æˆ– local_name ä¸ºç©º")
                        continue
                    
                    # éªŒè¯ disease_id æ˜¯å¦å­˜åœ¨äº standard_diseases
                    if disease_id not in valid_disease_ids:
                        warning_msg = f"æ˜ å°„çš„ disease_id ä¸å­˜åœ¨äºæ ‡å‡†åº“: {disease_id} (æœ¬åœ°åç§°: {local_name})"
                        logger.warning(f"  âš ï¸  {warning_msg}")
                        self.stats["warnings"].append(warning_msg)
                        continue
                    
                    if not self.dry_run:
                        await db.execute(text("""
                            INSERT INTO disease_mappings (
                                country_code, local_name, disease_id,
                                local_code, category, priority
                            ) VALUES (
                                :country, :local_name, :disease_id,
                                :local_code, :category, :priority
                            )
                            ON CONFLICT (country_code, local_name, disease_id) DO UPDATE SET
                                local_code = EXCLUDED.local_code,
                                category = EXCLUDED.category,
                                updated_at = CURRENT_TIMESTAMP
                        """), {
                            "country": self.country_code,
                            "local_name": local_name,
                            "disease_id": disease_id,
                            "local_code": local_code,
                            "category": category,
                            "priority": 100
                        })
                    
                    self.stats["mappings_added"] += 1
                    
                    # å¤„ç†åˆ«åï¼ˆå¦‚æœæœ‰ aliases åˆ—ï¼‰
                    if 'aliases' in row and pd.notna(row['aliases']) and row['aliases']:
                        aliases = [a.strip() for a in str(row['aliases']).split('|') if a.strip()]
                        for alias in aliases:
                            if not self.dry_run:
                                await db.execute(text("""
                                    INSERT INTO disease_mappings (
                                        country_code, local_name, disease_id, priority
                                    ) VALUES (
                                        :country, :alias, :disease_id, :priority
                                    )
                                    ON CONFLICT (country_code, local_name, disease_id) DO NOTHING
                                """), {
                                    "country": self.country_code,
                                    "alias": alias,
                                    "disease_id": disease_id,
                                    "priority": 90  # åˆ«åä¼˜å…ˆçº§ç¨ä½
                                })
                            self.stats["mappings_added"] += 1
                    
                    if (idx + 1) % 20 == 0:
                        logger.info(f"  è¿›åº¦: {idx + 1}/{len(df)}")
                
                except Exception as e:
                    error_msg = f"å¯¼å…¥æ˜ å°„å¤±è´¥ (è¡Œ {idx+2}): {e}"
                    logger.error(f"  âŒ {error_msg}")
                    self.stats["errors"].append(error_msg)
            
            if not self.dry_run:
                await db.commit()
            
            logger.info(f"  âœ“ å·²å¯¼å…¥ {self.stats['mappings_added']} æ¡æ˜ å°„ï¼ˆå«åˆ«åï¼‰")
    
    async def _validate_integrity(self):
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        async with get_db() as db:
            # 1. æ£€æŸ¥æ ‡å‡†ç–¾ç—…æ•°é‡
            result = await db.execute(text("SELECT COUNT(*) FROM standard_diseases"))
            std_count = result.scalar()
            logger.info(f"  âœ“ æ ‡å‡†ç–¾ç—…åº“: {std_count} æ¡è®°å½•")
            
            # 2. æ£€æŸ¥æ˜ å°„æ•°é‡
            result = await db.execute(text(
                f"SELECT COUNT(*) FROM disease_mappings WHERE country_code = '{self.country_code}'"
            ))
            map_count = result.scalar()
            logger.info(f"  âœ“ {self.country_code} å›½å®¶æ˜ å°„: {map_count} æ¡è®°å½•")
            
            # 3. æ£€æŸ¥å­¤ç«‹æ˜ å°„ï¼ˆæ˜ å°„çš„ disease_id ä¸å­˜åœ¨äºæ ‡å‡†åº“ï¼‰
            result = await db.execute(text("""
                SELECT dm.disease_id, COUNT(*) as cnt
                FROM disease_mappings dm
                LEFT JOIN standard_diseases sd ON dm.disease_id = sd.disease_id
                WHERE dm.country_code = :country AND sd.disease_id IS NULL
                GROUP BY dm.disease_id
            """), {"country": self.country_code})
            orphaned = result.fetchall()
            
            if orphaned:
                logger.warning(f"  âš ï¸  å‘ç° {len(orphaned)} ä¸ªå­¤ç«‹æ˜ å°„ï¼ˆdisease_id ä¸å­˜åœ¨äºæ ‡å‡†åº“ï¼‰:")
                for disease_id, cnt in orphaned[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    logger.warning(f"      - {disease_id}: {cnt} æ¡æ˜ å°„")
                if len(orphaned) > 5:
                    logger.warning(f"      ... è¿˜æœ‰ {len(orphaned) - 5} ä¸ª")
            
            # 4. æ£€æŸ¥é‡å¤æ˜ å°„
            result = await db.execute(text("""
                SELECT local_name, COUNT(DISTINCT disease_id) as cnt
                FROM disease_mappings
                WHERE country_code = :country
                GROUP BY local_name
                HAVING COUNT(DISTINCT disease_id) > 1
            """), {"country": self.country_code})
            duplicates = result.fetchall()
            
            if duplicates:
                logger.info(f"  â„¹ï¸  å‘ç° {len(duplicates)} ä¸ªæœ¬åœ°åç§°æœ‰å¤šä¸ªæ˜ å°„ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼Œä¼šæŒ‰ä¼˜å…ˆçº§é€‰æ‹©ï¼‰:")
                for local_name, cnt in duplicates[:5]:
                    logger.info(f"      - {local_name}: {cnt} ä¸ªæ˜ å°„")
    
    def _print_summary(self):
        """æ‰“å°æ±‡æ€»æŠ¥å‘Š"""
        logger.info("ğŸ“Š åˆ·æ–°ç»“æœæ±‡æ€»:")
        logger.info(f"  â€¢ æ ‡å‡†ç–¾ç—…: +{self.stats['standard_diseases_added']} æ¡")
        logger.info(f"  â€¢ å›½å®¶æ˜ å°„: +{self.stats['mappings_added']} æ¡")
        
        if self.stats["warnings"]:
            logger.warning(f"\nâš ï¸  è­¦å‘Š ({len(self.stats['warnings'])} æ¡):")
            for warning in self.stats["warnings"][:10]:
                logger.warning(f"  - {warning}")
            if len(self.stats["warnings"]) > 10:
                logger.warning(f"  ... è¿˜æœ‰ {len(self.stats['warnings']) - 10} æ¡è­¦å‘Š")
        
        if self.stats["errors"]:
            logger.error(f"\nâŒ é”™è¯¯ ({len(self.stats['errors'])} æ¡):")
            for error in self.stats["errors"][:10]:
                logger.error(f"  - {error}")
            if len(self.stats["errors"]) > 10:
                logger.error(f"  ... è¿˜æœ‰ {len(self.stats['errors']) - 10} æ¡é”™è¯¯")
        
        if not self.stats["errors"]:
            logger.info("\nâœ… åˆ·æ–°å®Œæˆï¼æ‰€æœ‰æ•°æ®å·²æˆåŠŸå¯¼å…¥")
        else:
            logger.error(f"\nâŒ åˆ·æ–°å®Œæˆä½†æœ‰ {len(self.stats['errors'])} ä¸ªé”™è¯¯")


async def main():
    parser = argparse.ArgumentParser(
        description="åˆ·æ–°ç–¾ç—…æ˜ å°„æ•°æ®åº“",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python scripts/refresh_disease_mappings.py                    # åˆ·æ–° CN æ˜ å°„
  python scripts/refresh_disease_mappings.py --country us       # åˆ·æ–° US æ˜ å°„
  python scripts/refresh_disease_mappings.py --dry-run          # ä»…éªŒè¯ä¸æ‰§è¡Œ
  python scripts/refresh_disease_mappings.py --yes              # è·³è¿‡ç¡®è®¤
        """
    )
    
    parser.add_argument(
        '--country',
        default='cn',
        help='å›½å®¶ä»£ç  (é»˜è®¤: cn)'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='ä»…éªŒè¯ä¸æ‰§è¡Œå®é™…æ“ä½œ'
    )
    parser.add_argument(
        '--yes', '-y',
        action='store_true',
        help='è·³è¿‡ç¡®è®¤æç¤º'
    )
    
    args = parser.parse_args()
    
    service = DiseaseRefreshService(
        country_code=args.country,
        dry_run=args.dry_run
    )
    
    success = await service.refresh_all(skip_confirmation=args.yes)
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    asyncio.run(main())
