"""
AI Report Generation Tests - Simplified

ç®€åŒ–çš„AIæŠ¥å‘Šç”Ÿæˆæµ‹è¯•ï¼Œæ•´åˆäº†æ‰€æœ‰æŠ¥å‘Šç›¸å…³åŠŸèƒ½æµ‹è¯•
ä½¿ç”¨çœŸå®æ•°æ®åº“æ•°æ®ï¼ˆ10å¹´ç™¾æ—¥å’³æ•°æ®ï¼‰è¿›è¡Œæµ‹è¯•
"""
import asyncio
import json
import sys
import tempfile
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
from unittest.mock import Mock, patch, AsyncMock

import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from src.core import get_config, get_database, get_logger, init_app
    from src.domain import Country, Disease, DiseaseRecord, ReportType
    from src.ai.agents import AnalystAgent, WriterAgent, ReviewerAgent
    from src.generation import ReportGenerator
    from sqlalchemy import select, func
    logger = get_logger(__name__)
    HAS_DEPENDENCIES = True
except ImportError as e:
    print(f"Warning: Could not import project modules: {e}")
    print("Running in standalone mode...")
    
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    HAS_DEPENDENCIES = False


class ReportGenerationTest:
    """æŠ¥å‘Šç”Ÿæˆæµ‹è¯•ç±» - æ•´åˆç‰ˆæœ¬"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•"""
        if not HAS_DEPENDENCIES:
            raise RuntimeError("Required dependencies not available")
            
        self.config = get_config()
        # Allow test to override reviewer threshold and retries via config for reproducibility
        try:
            self.config.ai.reviewer_threshold = 0.8
            self.config.ai.max_retries = 5
        except Exception:
            pass
        self.test_data_dir = Path(__file__).parent / "fixtures" / "ai_test_data"
        self.test_data_dir.mkdir(parents=True, exist_ok=True)
        
    async def find_pertussis_disease(self) -> Optional[Disease]:
        """æŸ¥æ‰¾ç™¾æ—¥å’³ç–¾ç—…"""
        async with get_database() as db:
            query = select(Disease).where(
                Disease.name.ilike('%ç™¾æ—¥å’³%') |
                Disease.name.ilike('%pertussis%') |
                Disease.name_en.ilike('%pertussis%')
            )
            
            result = await db.execute(query)
            disease = result.scalars().first()
            
            if disease:
                logger.info(f"Found pertussis disease: {disease.name} (ID: {disease.id})")
            return disease
    
    async def fetch_disease_data(self, years_back: int = 10) -> pd.DataFrame:
        """è·å–ç–¾ç—…æ•°æ®ï¼ˆæŒ‡å®šå¹´æ•°ï¼‰- å‡è®¾æ•°æ®å­˜åœ¨"""
        try:
            disease = await self.find_pertussis_disease()
            if not disease:
                raise RuntimeError("Pertussis disease not found in database")
            
            end_date = datetime.now()
            start_date = end_date - timedelta(days=years_back * 365)
            
            async with get_database() as db:
                # è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ‰€æœ‰æ•°æ®ï¼ˆä¸é™åˆ¶å›½å®¶ï¼‰
                query = select(
                    DiseaseRecord.time,
                    DiseaseRecord.cases,
                    DiseaseRecord.deaths,
                    DiseaseRecord.country_id,
                    DiseaseRecord.data_source,
                    Disease.name.label('disease_name'),
                    Disease.name_en.label('disease_name_en'),
                    Country.name.label('country_name'),
                    Country.code.label('country_code'),
                    Country.name_en.label('country_name_en')
                ).join(
                    Disease
                ).join(
                    Country
                ).where(
                    DiseaseRecord.disease_id == disease.id,
                    DiseaseRecord.time >= start_date,
                    DiseaseRecord.time <= end_date
                ).order_by(DiseaseRecord.time.desc()).limit(100)  # æœ€å¤š100æ¡è®°å½•
                
                result = await db.execute(query)
                rows = result.all()
                
                if not rows:
                    # è·å–æ‰€æœ‰å¯ç”¨æ•°æ®ï¼ˆæœ€æ–°50æ¡ï¼‰
                    query = select(
                        DiseaseRecord.time,
                        DiseaseRecord.cases,
                        DiseaseRecord.deaths,
                        DiseaseRecord.country_id,
                        DiseaseRecord.data_source,
                        Disease.name.label('disease_name'),
                        Disease.name_en.label('disease_name_en'),
                        Country.name.label('country_name'),
                        Country.code.label('country_code'),
                        Country.name_en.label('country_name_en')
                    ).join(
                        Disease
                    ).join(
                        Country
                    ).where(
                        DiseaseRecord.disease_id == disease.id
                    ).order_by(DiseaseRecord.time.desc()).limit(50)
                    
                    result = await db.execute(query)
                    rows = result.all()
                
                # è½¬æ¢ä¸ºDataFrame with enhanced context
                data = pd.DataFrame([{
                    'date': row.time,
                    'disease_name': row.disease_name,
                    'disease_name_en': row.disease_name_en or 'Pertussis',
                    'case_count': row.cases or 0,
                    'death_count': row.deaths or 0,
                    'country_id': row.country_id,
                    'country_name': row.country_name,
                    'country_code': row.country_code,
                    'country_name_en': row.country_name_en,
                    'source': row.data_source or 'Database'
                } for row in rows])
                
                logger.info(f"Fetched {len(data)} disease records")
                return data
                
        except Exception as e:
            logger.error(f"Failed to fetch disease data: {e}")
            raise
    
    async def test_analyst_agent(self, data: pd.DataFrame) -> Dict:
        """æµ‹è¯•åˆ†æAgent"""
        print("ğŸ“Š æµ‹è¯• AnalystAgent...")
        
        try:
            analyst = AnalystAgent()
            
            # Enhanced analysis task with more context
            disease_name = data['disease_name'].iloc[0] if len(data) > 0 else 'Unknown'
            disease_name_en = data['disease_name_en'].iloc[0] if len(data) > 0 else 'Unknown'
            countries = data['country_name_en'].unique().tolist() if len(data) > 0 else ['Unknown']
            date_range = (data['date'].min(), data['date'].max()) if len(data) > 0 else (None, None)
            
            logger.info(f"Testing analyst with {disease_name_en} in {countries}, {len(data)} records")
            
            result = await analyst.process(
                data=data,
                disease_name=disease_name_en,
                period_start=date_range[0] or datetime.now() - timedelta(days=365),
                period_end=date_range[1] or datetime.now(),
                geographical_scope=countries,
                data_sources=data['source'].unique().tolist() if len(data) > 0 else ['Database']
            )
            
            print(f"   âœ… åˆ†æå®Œæˆ - æ‰¾åˆ° {len(result.get('patterns', []))} ä¸ªæ¨¡å¼")
            return result
            
        except Exception as e:
            print(f"   âŒ åˆ†æå¤±è´¥: {e}")
            logger.exception("Analyst test failed")
            raise
    
    async def test_writer_agent_with_retry(self, analysis_data: Dict, disease_name: str = None, 
                                          table_data_str: str = None, max_retries: int = 2) -> Dict:
        """Test WriterAgent with reviewer feedback and retry mechanism"""
        print(f"ğŸ“ Testing WriterAgent (4-section structured report, up to {max_retries} retries)...")
        
        sections = ['introduction', 'highlights', 'cases_analysis', 'deaths_analysis']
        report_sections = {}
        report_date = datetime.now().strftime('%Y-%m-%d')
        
        writer = WriterAgent()
        reviewer = ReviewerAgent()
        # Use reviewer-configured threshold and retries when available
        configured_threshold = getattr(reviewer, 'reviewer_threshold', 0.8)
        configured_max_retries = getattr(reviewer, 'max_retries', max_retries)
        max_retries = configured_max_retries
        
        for section_type in sections:
            print(f"   ğŸ”¤ ç”Ÿæˆ {section_type} éƒ¨åˆ†...")
            
            retry_count = 0
            section_approved = False
            
            while retry_count <= max_retries and not section_approved:
                try:
                    # Generate section content. If we have revision instructions from a previous review, pass them.
                    revision_instructions = None
                    if retry_count > 0 and 'suggestions' in locals():
                        revision_instructions = '; '.join(suggestions)

                    result = await writer.process(
                        section_type=section_type,
                        analysis_data=analysis_data,
                        language='en',
                        style='formal',
                        disease_name=disease_name or 'Pertussis',
                        report_date=report_date,
                        table_data_str=table_data_str,
                        revision_instructions=revision_instructions,
                    )
                    
                    content = result.get('content', '')
                    
                    # Review the content
                    review_result = await reviewer.process(
                        content=content,
                        content_type=section_type
                    )
                    
                    overall_score = review_result.get('quality_score', {}).get('overall', 0)
                    approved = review_result.get('approved', False)
                    
                    if approved or overall_score >= configured_threshold:
                        # Content approved
                        report_sections[section_type] = {
                            'content': content,
                            'word_count': result.get('word_count', 0),
                            'length': len(content),
                            'score': overall_score,
                            'attempts': retry_count + 1
                        }
                        section_approved = True
                        print(f"   âœ… {section_type}: {len(content)} chars, score {overall_score:.2f}, passed at attempt {retry_count + 1}")
                    else:
                        # Content needs revision
                        retry_count += 1
                        suggestions = review_result.get('suggestions', [])
                        print(f"   ğŸ—’ï¸ {section_type}: score {overall_score:.2f}, retry {retry_count}...")
                        print(f"      Suggestions: {len(suggestions)} items")
                        
                        if retry_count > max_retries:
                            # Max retries reached, use content anyway
                            report_sections[section_type] = {
                                'content': content,
                                'word_count': result.get('word_count', 0),
                                'length': len(content),
                                'score': overall_score,
                                'attempts': retry_count,
                                'final_status': 'max_retries_reached'
                            }
                            print(f"   âš ï¸ {section_type}: reached max retries, using current version")
                            section_approved = True
                except Exception as e:
                    print(f"   âŒ {section_type} generation failed: {e}")
                    retry_count += 1
                    if retry_count > max_retries:
                        raise
        
        # Combine all sections
        combined_content = f"""# {disease_name or 'Pertussis'} Surveillance Report

## Introduction
{report_sections['introduction']['content']}

## Highlights
{report_sections['highlights']['content']}

## Cases Analysis
{report_sections['cases_analysis']['content']}

## Deaths Analysis
{report_sections['deaths_analysis']['content']}"""
        
        total_length = len(combined_content)
        total_attempts = sum(section.get('attempts', 1) for section in report_sections.values())
        
        print(f"   âœ… å®Œæ•´æŠ¥å‘Šç”Ÿæˆ - æ€»è®¡ {total_length} å­—ç¬¦, {total_attempts} æ¬¡ç”Ÿæˆå°è¯•")
        
        return {
            'content': combined_content,
            'sections': report_sections,
            'total_length': total_length,
            'section_count': len(sections),
            'total_attempts': total_attempts
        }
    
    async def test_reviewer_agent(self, content: str) -> Dict:
        """æµ‹è¯•å®¡æ ¸Agent"""
        print("ğŸ” æµ‹è¯• ReviewerAgent...")
        
        try:
            reviewer = ReviewerAgent()
            
            result = await reviewer.process(
                content=content,
                content_type='report'
            )
            
            score = result.get('quality_score', {}).get('overall', 0)
            print(f"   âœ… å®¡æ ¸å®Œæˆ - è¯„åˆ†: {score:.2f}/1.0")
            return result
            
        except Exception as e:
            print(f"   âŒ å®¡æ ¸å¤±è´¥: {e}")
            logger.exception("Reviewer test failed")
            raise
    
    async def test_complete_pipeline(self) -> Dict[str, Any]:
        """æµ‹è¯•å®Œæ•´çš„æŠ¥å‘Šç”Ÿæˆæµæ°´çº¿"""
        print("ğŸ”„ æµ‹è¯•å®Œæ•´AIæŠ¥å‘Šç”Ÿæˆæµæ°´çº¿...")
        
        test_results = {
            'pipeline_test': True,
            'start_time': datetime.now().isoformat(),
            'stages': {}
        }
        
        try:
            # 1. æ•°æ®è·å–
            print("\nç¬¬ä¸€é˜¶æ®µ: æ•°æ®è·å–")
            data = await self.fetch_disease_data(years_back=10)
            
            test_results['stages']['data_fetch'] = {
                'status': 'success',
                'records_count': len(data),
                'date_range': {
                    'start': data['date'].min().isoformat() if len(data) > 0 else None,
                    'end': data['date'].max().isoformat() if len(data) > 0 else None
                },
                'diseases': data['disease_name'].unique().tolist()
            }
            
            print(f"   âœ… è·å–äº† {len(data)} æ¡è®°å½•")
            
            # ä¿å­˜æ•°æ®æ ·æœ¬
            sample_file = self.test_data_dir / f"disease_data_sample_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            data.to_csv(sample_file, index=False)
            print(f"   ğŸ’¾ æ•°æ®æ ·æœ¬ä¿å­˜åˆ°: {sample_file}")
            
            # 2. AIåˆ†æ
            print("\nç¬¬äºŒé˜¶æ®µ: AIæ•°æ®åˆ†æ")
            analysis_result = await self.test_analyst_agent(data)
            
            test_results['stages']['analysis'] = {
                'status': 'success',
                'patterns_found': len(analysis_result.get('patterns', [])),
                'insights_count': len(analysis_result.get('insights', []))
            }
            
            # 3. æŠ¥å‘Šå†™ä½œ (å››éƒ¨åˆ†ç»“æ„åŒ–)
            print("\nç¬¬ä¸‰é˜¶æ®µ: ç»“æ„åŒ–æŠ¥å‘Šå†™ä½œ")
            
            # å‡†å¤‡æ•°æ®å­—ç¬¦ä¸²
            disease_name = data['disease_name_en'].iloc[0] if len(data) > 0 else 'Pertussis'
            table_data_str = data.to_string(index=False, max_rows=10) if len(data) > 0 else "No data available"
            
            writing_result = await self.test_writer_agent_with_retry(
                analysis_result, 
                disease_name=disease_name, 
                table_data_str=table_data_str
            )
            
            content = writing_result.get('content', '')
            test_results['stages']['writing'] = {
                'status': 'success',
                'content_length': len(content),
                'section_count': writing_result.get('section_count', 0),
                'sections': list(writing_result.get('sections', {}).keys()),
                'content_preview': content[:200] + '...' if len(content) > 200 else content
            }
            
            # 4. å†…å®¹å®¡æ ¸
            print("\nç¬¬å››é˜¶æ®µ: å†…å®¹å®¡æ ¸")
            review_result = await self.test_reviewer_agent(content)
            
            test_results['stages']['review'] = {
                'status': 'success',
                'score': review_result.get('quality_score', {}).get('overall', 0),
                'approved': review_result.get('approved', False),
                'suggestions_count': len(review_result.get('suggestions', []))
            }
            
            # 5. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                'report_id': f"ai_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                'generated_at': datetime.now().isoformat(),
                'data_summary': test_results['stages']['data_fetch'],
                'analysis_results': analysis_result,
                'report_content': content,
                'review_results': review_result
            }
            
            # ä¿å­˜å®Œæ•´æŠ¥å‘Š (JSON)
            report_file = self.test_data_dir / f"complete_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(final_report, f, ensure_ascii=False, indent=2, default=str)
            
            # ç”Ÿæˆ Markdown æŠ¥å‘Š
            markdown_file = self.test_data_dir / f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            self._generate_markdown_report(final_report, markdown_file)
            
            test_results['final_report_file'] = str(report_file)
            test_results['markdown_report_file'] = str(markdown_file)
            test_results['status'] = 'success'
            
            print(f"\nâœ… å®Œæ•´æµæ°´çº¿æµ‹è¯•æˆåŠŸ!")
            print(f"ğŸ“„ JSONæŠ¥å‘Šä¿å­˜åˆ°: {report_file}")
            print(f"ğŸ“‹ MarkdownæŠ¥å‘Šä¿å­˜åˆ°: {markdown_file}")
            
            return test_results
            
        except Exception as e:
            test_results['status'] = 'failed'
            test_results['error'] = str(e)
            logger.exception("Pipeline test failed")
            return test_results
    
    def print_summary(self, results: Dict[str, Any]):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“‹ AIæŠ¥å‘Šç”Ÿæˆæµ‹è¯•æ‘˜è¦")
        print("="*60)
        
        if results.get('status') == 'success':
            print("ğŸ‰ æ•´ä½“çŠ¶æ€: æˆåŠŸ")
        else:
            print("âŒ æ•´ä½“çŠ¶æ€: å¤±è´¥")
            if 'error' in results:
                print(f"   é”™è¯¯: {results['error']}")
        
        if 'stages' in results:
            print(f"\né˜¶æ®µç»“æœ:")
            for stage_name, stage_result in results['stages'].items():
                status_emoji = "âœ…" if stage_result.get('status') == 'success' else "âŒ"
                print(f"  {status_emoji} {stage_name}: {stage_result.get('status')}")
                
                if stage_name == 'data_fetch' and stage_result.get('status') == 'success':
                    print(f"      è®°å½•æ•°: {stage_result.get('records_count')}")
                    print(f"      ç–¾ç—…: {', '.join(stage_result.get('diseases', []))}")
                elif stage_name == 'analysis' and stage_result.get('status') == 'success':
                    print(f"      æ¨¡å¼æ•°: {stage_result.get('patterns_found')}")
                    print(f"      æ´å¯Ÿæ•°: {stage_result.get('insights_count')}")
                elif stage_name == 'writing' and stage_result.get('status') == 'success':
                    print(f"      å†…å®¹é•¿åº¦: {stage_result.get('content_length')} å­—ç¬¦")
                    section_count = stage_result.get('section_count', 0)
                    sections = stage_result.get('sections', [])
                    print(f"      éƒ¨åˆ†æ•°: {section_count} (åŒ…å«: {', '.join(sections)})")
                elif stage_name == 'review' and stage_result.get('status') == 'success':
                    print(f"      è¯„åˆ†: {stage_result.get('score'):.2f}/1.0")
                    print(f"      çŠ¶æ€: {'âœ… é€šè¿‡' if stage_result.get('approved', False) else 'ğŸ—’ï¸ å¾…ä¿®æ”¹'}")
        
        if 'final_report_file' in results:
            print(f"\nğŸ“„ JSONæŠ¥å‘Š: {results['final_report_file']}")
        if 'markdown_report_file' in results:
            print(f"ğŸ“‹ MarkdownæŠ¥å‘Š: {results['markdown_report_file']}")

    def _generate_markdown_report(self, report_data: Dict[str, Any], output_file: Path):
        """ç”Ÿæˆ Markdown æ ¼å¼çš„æŠ¥å‘Š"""
        try:
            # æå–æŠ¥å‘Šå†…å®¹
            content = report_data.get('report_content', '')
            analysis_results = report_data.get('analysis_results', {})
            review_results = report_data.get('review_results', {})
            data_summary = report_data.get('data_summary', {})
            
            # ç”Ÿæˆ Markdown å†…å®¹
            markdown_content = f"""# AI Disease Surveillance Report

**Report ID**: {report_data.get('report_id', 'Unknown')}
**Generated**: {report_data.get('generated_at', 'Unknown')}
**Disease**: {analysis_results.get('disease_name', 'Unknown')}
**Period**: {analysis_results.get('period', {}).get('start', 'Unknown')} - {analysis_results.get('period', {}).get('end', 'Unknown')}
**Data Records**: {data_summary.get('records_count', 0)}

---

{content}

---

## Analysis Summary

### Statistical Overview
- **Total Records**: {data_summary.get('records_count', 0)}
- **Time Range**: {data_summary.get('date_range', {}).get('start', 'N/A')} to {data_summary.get('date_range', {}).get('end', 'N/A')}
- **Diseases Covered**: {', '.join(data_summary.get('diseases', []))}

### Quality Assessment
- **Overall Score**: {review_results.get('quality_score', {}).get('overall', 'N/A'):.2f}/1.0
- **Accuracy**: {review_results.get('quality_score', {}).get('accuracy', 'N/A'):.2f}
- **Completeness**: {review_results.get('quality_score', {}).get('completeness', 'N/A'):.2f}
- **Clarity**: {review_results.get('quality_score', {}).get('clarity', 'N/A'):.2f}
- **Professional Standards**: {review_results.get('quality_score', {}).get('professionalism', 'N/A'):.2f}
- **Report Status**: {'âœ… Approved' if review_results.get('approved', False) else 'âŒ Needs Revision'}

### Review Assessment
{review_results.get('assessment', 'No assessment available')}

### Expert Recommendations
{chr(10).join([f"- {suggestion}" for suggestion in review_results.get('suggestions', ['No specific suggestions provided'])])}

---

**Generated by GlobalID v2.0 AI Report Generation System**
"""
            
            # å†™å…¥ Markdown æ–‡ä»¶
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
                
            print(f"   ğŸ“‹ MarkdownæŠ¥å‘Šç”ŸæˆæˆåŠŸ: {len(markdown_content)} å­—ç¬¦")
            
        except Exception as e:
            logger.error(f"Failed to generate Markdown report: {e}")
            print(f"   âŒ MarkdownæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ§ª AIæŠ¥å‘Šç”Ÿæˆæµ‹è¯• (10å¹´ç™¾æ—¥å’³æ•°æ®)")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–åº”ç”¨ - å¼‚æ­¥è°ƒç”¨
        await init_app()
        
        # åˆ›å»ºæµ‹è¯•å®ä¾‹
        test = ReportGenerationTest()
        
        # è¿è¡Œå®Œæ•´æµ‹è¯•
        results = await test.test_complete_pipeline()
        
        # æ‰“å°æ‘˜è¦
        test.print_summary(results)
        
        # è¿”å›ç»“æœ
        if results.get('status') == 'success':
            print("\nğŸ‰ æ‰€æœ‰AIæŠ¥å‘Šç”Ÿæˆæµ‹è¯•é€šè¿‡!")
            exit(0)
        else:
            print(f"\nğŸ˜ AIæŠ¥å‘Šç”Ÿæˆæµ‹è¯•å¤±è´¥")
            exit(1)
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        logger.exception("Main test failed")
        exit(1)


if __name__ == "__main__":
    asyncio.run(main())