# å¤šAIåä½œä¸éªŒè¯ç³»ç»Ÿè¯¦ç»†è®¾è®¡

## ğŸ¤– AI Agentåä½œæ¶æ„

### è®¾è®¡ç†å¿µ

**ä¸æ˜¯AIéªŒè¯AIï¼Œè€Œæ˜¯AIä¸“å®¶å›¢é˜Ÿåä½œ**

```
ä¼ ç»Ÿæ–¹å¼ï¼ˆé—®é¢˜ï¼‰:
Writer AI â†’ ç”Ÿæˆå†…å®¹ â†’ Validator AI â†’ è¯´"ä¸è¡Œ" â†’ é‡è¯• â†’ æµªè´¹

æ–°æ–¹å¼ï¼ˆè§£å†³æ–¹æ¡ˆï¼‰:
å¤šä¸ªä¸“å®¶AI â†’ åˆ†å·¥åä½œ â†’ äº¤å‰å®¡æŸ¥ â†’ è¾¾æˆå…±è¯† â†’ é«˜è´¨é‡è¾“å‡º
```

---

## ğŸ­ AIä¸“å®¶è§’è‰²è®¾è®¡

### 1. æ•°æ®åˆ†æä¸“å®¶ (Analyst Agent)

**èŒè´£**: åˆ†ææ•°æ®ï¼Œæå–æ´å¯Ÿ

```python
# src/ai/agents/analyst.py

class AnalystAgent(BaseAgent):
    """æ•°æ®åˆ†æä¸“å®¶ - ä¸å†™ä½œï¼Œåªåˆ†æ"""
    
    role = """
    You are an epidemiologist and data analyst. 
    Your job is to analyze disease data and extract key insights.
    DO NOT write reports - only provide analytical findings.
    """
    
    async def analyze(self, data: pd.DataFrame, disease: str) -> AnalysisReport:
        """
        åˆ†ææ•°æ®ï¼Œè¾“å‡ºç»“æ„åŒ–å‘ç°
        """
        
        prompt = f"""
        Analyze the {disease} data and provide structured insights:
        
        Data summary:
        - Time period: {data['Date'].min()} to {data['Date'].max()}
        - Total cases: {data['Cases'].sum()}
        - Total deaths: {data['Deaths'].sum()}
        
        Detailed data:
        {data.to_string()}
        
        Provide analysis in JSON format:
        {{
            "trends": {{
                "overall": "increasing/decreasing/stable",
                "recent_change": "percentage change in last period",
                "seasonality": "observed patterns"
            }},
            "key_statistics": {{
                "peak_month": "month with highest cases",
                "lowest_month": "month with lowest cases",
                "case_fatality_rate": "average CFR"
            }},
            "notable_events": [
                {{
                    "date": "when",
                    "event": "what happened",
                    "impact": "significance"
                }}
            ],
            "risk_assessment": "low/medium/high with reason",
            "data_quality": {{
                "completeness": 0.0-1.0,
                "anomalies": ["list of issues"],
                "confidence": 0.0-1.0
            }}
        }}
        
        Be objective and data-driven. Flag uncertainties.
        """
        
        response = await self.llm.generate(
            prompt,
            model="gpt-4o",
            response_format="json",
            temperature=0.3  # ä½æ¸©åº¦ï¼Œæ›´å®¢è§‚
        )
        
        return AnalysisReport.parse_raw(response)


### 2. å†™ä½œä¸“å®¶ (Writer Agent)

**èŒè´£**: åŸºäºåˆ†æç»“æœï¼Œæ’°å†™ä¸“ä¸šæŠ¥å‘Š

```python
# src/ai/agents/writer.py

class WriterAgent(BaseAgent):
    """å†™ä½œä¸“å®¶ - åŸºäºäº‹å®å†™ä½œï¼Œä¸åšåˆ†æ"""
    
    role = """
    You are a medical writer specializing in epidemiological reports.
    You write clear, professional content based on provided analysis.
    DO NOT analyze data - use the analysis provided to you.
    """
    
    async def write_section(self,
                           section_type: str,  # introduction, highlightsç­‰
                           analysis: AnalysisReport,
                           context: Dict,
                           style: str = "professional") -> str:
        """
        åŸºäºåˆ†æç»“æœå†™ä½œ
        """
        
        # è·å–sectionæ¨¡æ¿å’ŒæŒ‡å¯¼
        guidelines = self._get_writing_guidelines(section_type)
        
        prompt = f"""
        Write the {section_type} section for a {analysis.disease} report.
        
        Analysis findings (from data analyst):
        {analysis.to_prompt_format()}
        
        Context:
        - Location: {context['location']}
        - Period: {context['period']}
        - Audience: {context['audience']}
        
        Writing guidelines:
        {guidelines}
        
        Requirements:
        1. Use ONLY the facts from the analysis
        2. Write in professional medical English
        3. Length: {context['expected_length']} words
        4. Style: {style}
        5. Include specific numbers and dates
        
        Output format:
        {{
            "content": "the written text",
            "word_count": number,
            "key_points_covered": ["point1", "point2"],
            "sources_used": ["which analysis elements were used"]
        }}
        """
        
        response = await self.llm.generate(
            prompt,
            model="gpt-4o",
            response_format="json",
            temperature=0.7  # é€‚ä¸­æ¸©åº¦ï¼Œå…è®¸åˆ›é€ æ€§è¡¨è¾¾
        )
        
        result = json.loads(response)
        return result['content']


### 3. å®¡æŸ¥ä¸“å®¶ (Reviewer Agent)

**èŒè´£**: å®¡æŸ¥å†…å®¹è´¨é‡ï¼Œæä¾›æ”¹è¿›å»ºè®®

```python
# src/ai/agents/reviewer.py

class ReviewerAgent(BaseAgent):
    """å®¡æŸ¥ä¸“å®¶ - ä»è¯»è€…è§’åº¦è¯„ä¼°è´¨é‡"""
    
    role = """
    You are a senior medical editor reviewing epidemiological reports.
    You check for accuracy, clarity, and completeness.
    You provide specific, actionable feedback.
    """
    
    async def review(self,
                    content: str,
                    analysis: AnalysisReport,
                    section_type: str) -> ReviewResult:
        """
        å®¡æŸ¥å†…å®¹ï¼Œç»™å‡ºè¯¦ç»†åé¦ˆ
        """
        
        prompt = f"""
        Review this {section_type} section:
        
        Content:
        {content}
        
        Original data analysis:
        {analysis.to_prompt_format()}
        
        Evaluation criteria:
        1. Factual accuracy: Does content match the analysis?
        2. Clarity: Is it easy to understand?
        3. Completeness: Are key points covered?
        4. Professional tone: Appropriate language?
        5. Structure: Logical flow?
        
        Provide detailed review in JSON:
        {{
            "overall_score": 0.0-1.0,
            "dimension_scores": {{
                "factual_accuracy": 0.0-1.0,
                "clarity": 0.0-1.0,
                "completeness": 0.0-1.0,
                "professionalism": 0.0-1.0,
                "structure": 0.0-1.0
            }},
            "strengths": ["what is good"],
            "issues": [
                {{
                    "severity": "minor/major/critical",
                    "description": "what is wrong",
                    "suggestion": "how to fix",
                    "line": "which part"
                }}
            ],
            "missing_elements": ["what should be added"],
            "recommendation": "approve/revise/reject"
        }}
        
        Be constructive and specific.
        """
        
        response = await self.llm.generate(
            prompt,
            model="claude-3-5-sonnet",  # ä½¿ç”¨ä¸åŒæ¨¡å‹è·å¾—ä¸åŒè§†è§’
            response_format="json",
            temperature=0.5
        )
        
        return ReviewResult.parse_raw(response)


### 4. äº‹å®æ ¸æŸ¥ä¸“å®¶ (Fact Checker Agent)

**èŒè´£**: éªŒè¯æ•°æ®å‡†ç¡®æ€§ï¼Œæ£€æŸ¥é€»è¾‘é”™è¯¯

```python
# src/ai/agents/fact_checker.py

class FactCheckerAgent(BaseAgent):
    """äº‹å®æ ¸æŸ¥ä¸“å®¶ - éªŒè¯æ•°å€¼å’Œé€»è¾‘"""
    
    async def check(self,
                   content: str,
                   analysis: AnalysisReport,
                   raw_data: pd.DataFrame) -> FactCheckResult:
        """
        æ ¸æŸ¥å†…å®¹ä¸­çš„äº‹å®é™ˆè¿°
        """
        
        # æå–å†…å®¹ä¸­çš„æ•°å­—å’Œå£°æ˜
        claims = self._extract_claims(content)
        
        verification_results = []
        
        for claim in claims:
            # å¯¹äºæ•°å­—å£°æ˜ï¼Œç›´æ¥éªŒè¯
            if claim.type == "numeric":
                is_correct = self._verify_against_data(claim, raw_data)
                verification_results.append({
                    'claim': claim.text,
                    'verified': is_correct,
                    'evidence': claim.source_data
                })
            
            # å¯¹äºå®šæ€§å£°æ˜ï¼Œç”¨LLMéªŒè¯é€»è¾‘
            elif claim.type == "qualitative":
                is_logical = await self._verify_logic(claim, analysis)
                verification_results.append({
                    'claim': claim.text,
                    'verified': is_logical,
                    'reasoning': claim.reasoning
                })
        
        return FactCheckResult(
            all_correct=all(r['verified'] for r in verification_results),
            details=verification_results
        )
```

---

## ğŸ”„ åä½œå·¥ä½œæµ

### Workflow 1: å•sectionç”Ÿæˆï¼ˆæ ‡å‡†æµç¨‹ï¼‰

```python
# src/generation/report/generator.py

class CollaborativeReportGenerator:
    """åä½œå¼æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.analyst = AnalystAgent()
        self.writer = WriterAgent()
        self.reviewer = ReviewerAgent()
        self.fact_checker = FactCheckerAgent()
        self.validator = EnsembleValidator()
        
    async def generate_section(self,
                               section_type: str,
                               data: pd.DataFrame,
                               disease: str,
                               max_iterations: int = 3) -> str:
        """
        åä½œç”Ÿæˆé«˜è´¨é‡section
        
        æµç¨‹ï¼š
        1. Analyståˆ†ææ•°æ®
        2. WriteråŸºäºåˆ†æå†™ä½œ
        3. Reviewerå®¡æŸ¥
        4. Fact Checkeræ ¸æŸ¥
        5. æ ¹æ®åé¦ˆè¿­ä»£æ”¹è¿›
        """
        
        # Stage 1: æ•°æ®åˆ†æ
        logger.info(f"[Analyst] Analyzing data for {disease} {section_type}")
        analysis = await self.analyst.analyze(data, disease)
        
        # æ£€æŸ¥åˆ†æè´¨é‡
        if analysis.data_quality.confidence < 0.7:
            logger.warning(f"Low confidence in analysis: {analysis.data_quality}")
            # å¯ä»¥é€‰æ‹©é™çº§æˆ–ä½¿ç”¨æ¨¡æ¿
        
        iteration = 0
        content = None
        review = None
        
        while iteration < max_iterations:
            iteration += 1
            logger.info(f"[Iteration {iteration}] Generating {section_type}")
            
            # Stage 2: å†™ä½œ
            if iteration == 1:
                # é¦–æ¬¡å†™ä½œ
                content = await self.writer.write_section(
                    section_type=section_type,
                    analysis=analysis,
                    context=self._get_context(disease)
                )
            else:
                # æ ¹æ®å®¡æŸ¥æ„è§æ”¹è¿›
                content = await self.writer.revise_section(
                    original=content,
                    review=review,
                    analysis=analysis
                )
            
            # Stage 3: å¿«é€Ÿè§„åˆ™éªŒè¯
            rule_valid, rule_result = await self.validator.validate(
                content, section_type, {}, strategy="fast"
            )
            
            if not rule_valid:
                logger.warning(f"Rule validation failed: {rule_result.issues}")
                # è§„åˆ™éªŒè¯å¤±è´¥ï¼Œç›´æ¥é‡è¯•
                continue
            
            # Stage 4: äº‹å®æ ¸æŸ¥
            fact_check = await self.fact_checker.check(
                content, analysis, data
            )
            
            if not fact_check.all_correct:
                logger.warning(f"Fact check failed: {fact_check.details}")
                # äº‹å®é”™è¯¯ï¼Œé‡æ–°å†™ä½œ
                continue
            
            # Stage 5: ä¸“ä¸šå®¡æŸ¥
            review = await self.reviewer.review(
                content, analysis, section_type
            )
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°è´¨é‡æ ‡å‡†
            if review.overall_score >= 0.8 and review.recommendation != "reject":
                logger.info(f"âœ“ High quality achieved (score: {review.overall_score})")
                break
            
            # å¦‚æœæœ‰ä¸¥é‡é—®é¢˜ï¼Œè®°å½•ä½†ç»§ç»­ï¼ˆé¿å…æ— é™å¾ªç¯ï¼‰
            if review.recommendation == "reject" and iteration >= max_iterations:
                logger.error(f"Quality issues remain after {max_iterations} iterations")
                # è®°å½•åˆ°äººå·¥å®¡æŸ¥é˜Ÿåˆ—
                await self._queue_for_human_review(content, review)
        
        # æœ€ç»ˆéªŒè¯
        final_valid, final_result = await self.validator.validate(
            content, section_type, {}, strategy="standard"
        )
        
        if not final_valid:
            # ä½¿ç”¨é™çº§ç­–ç•¥
            logger.warning("Final validation failed, using fallback")
            fallback_handler = SmartFallbackHandler()
            success, content, strategy = await fallback_handler.handle_failure(
                task=section_type,
                error=Exception("Validation failed"),
                context={'disease': disease, 'analysis': analysis}
            )
        
        return content, {
            'iterations': iteration,
            'final_score': review.overall_score if review else 0,
            'analysis_confidence': analysis.data_quality.confidence,
            'fact_check': fact_check.all_correct
        }
```

**æµç¨‹å›¾**ï¼š

```mermaid
graph TB
    Start[å¼€å§‹] --> Analyze[Analyst: åˆ†ææ•°æ®]
    Analyze --> CheckQuality{åˆ†æè´¨é‡OK?}
    CheckQuality -->|ä½è´¨é‡| Fallback1[ä½¿ç”¨æ¨¡æ¿]
    CheckQuality -->|OK| Write[Writer: å†™ä½œå†…å®¹]
    
    Write --> RuleCheck{è§„åˆ™éªŒè¯}
    RuleCheck -->|å¤±è´¥| Write
    
    RuleCheck -->|é€šè¿‡| FactCheck[Fact Checker: äº‹å®æ ¸æŸ¥]
    FactCheck -->|æœ‰é”™è¯¯| Write
    
    FactCheck -->|é€šè¿‡| Review[Reviewer: ä¸“ä¸šå®¡æŸ¥]
    Review --> ScoreCheck{è´¨é‡åˆ†æ•° >= 0.8?}
    
    ScoreCheck -->|å¦| IterCheck{è¿­ä»£æ¬¡æ•° < 3?}
    IterCheck -->|æ˜¯| Revise[Writer: æ ¹æ®åé¦ˆä¿®è®¢]
    Revise --> RuleCheck
    
    IterCheck -->|å¦| HumanQueue[åŠ å…¥äººå·¥å®¡æŸ¥é˜Ÿåˆ—]
    HumanQueue --> Return[è¿”å›å½“å‰æœ€ä½³ç‰ˆæœ¬]
    
    ScoreCheck -->|æ˜¯| FinalCheck[æœ€ç»ˆéªŒè¯]
    FinalCheck --> Success{é€šè¿‡?}
    Success -->|æ˜¯| Done[å®Œæˆ]
    Success -->|å¦| Fallback2[æ™ºèƒ½é™çº§]
    Fallback2 --> Done
    
    Fallback1 --> Done
    
    style Analyze fill:#e3f2fd
    style Write fill:#f3e5f5
    style Review fill:#fff3e0
    style FactCheck fill:#e8f5e9
    style Done fill:#c8e6c9
```

### Workflow 2: å¤šä¸“å®¶Panelè®¨è®ºï¼ˆå¤æ‚å†…å®¹ï¼‰

```python
class ExpertPanel:
    """ä¸“å®¶å°ç»„ - ç”¨äºå¤æ‚æˆ–æœ‰äº‰è®®çš„å†…å®¹"""
    
    def __init__(self):
        self.experts = [
            AnalystAgent(model="gpt-4o"),
            AnalystAgent(model="claude-3-5-sonnet"),  # ä¸åŒè§†è§’
            ReviewerAgent(model="gpt-4o-mini"),
        ]
        
    async def discuss(self, topic: str, data: Any) -> Consensus:
        """
        ä¸“å®¶å°ç»„è®¨è®º
        
        åœºæ™¯ï¼š
        - æ•°æ®å¼‚å¸¸æˆ–çŸ›ç›¾
        - è¶‹åŠ¿è§£é‡Šæœ‰æ­§ä¹‰
        - é£é™©è¯„ä¼°ä¸ç¡®å®š
        """
        
        # æ¯ä¸ªä¸“å®¶ç‹¬ç«‹åˆ†æ
        individual_analyses = []
        for expert in self.experts:
            analysis = await expert.analyze(data, topic)
            individual_analyses.append(analysis)
        
        # æ£€æŸ¥ä¸“å®¶ä¹‹é—´çš„åˆ†æ­§
        disagreements = self._find_disagreements(individual_analyses)
        
        if not disagreements:
            # ä¸“å®¶ä¸€è‡´ï¼Œç›´æ¥é‡‡çº³
            return Consensus(
                agreed=True,
                result=individual_analyses[0],
                confidence=0.95
            )
        
        # æœ‰åˆ†æ­§ï¼Œè¿›è¡Œè°ƒè§£
        logger.info(f"Experts disagree on: {disagreements}")
        
        # è®©ä¸€ä¸ªé«˜çº§AIè°ƒè§£
        moderator_prompt = f"""
        Multiple experts analyzed the {topic} data but have disagreements:
        
        Expert 1 (GPT-4):
        {individual_analyses[0].summary()}
        
        Expert 2 (Claude):
        {individual_analyses[1].summary()}
        
        Expert 3 (Reviewer):
        {individual_analyses[2].summary()}
        
        Disagreements:
        {disagreements}
        
        Raw data:
        {data.describe()}
        
        As a senior moderator, provide:
        1. Which interpretation is most likely correct and why
        2. A unified analysis that reconciles differences
        3. Confidence level in the conclusion
        4. Any remaining uncertainties
        
        Return JSON format.
        """
        
        consensus = await self.moderator.generate(moderator_prompt)
        
        return Consensus(
            agreed=False,
            result=consensus,
            confidence=consensus.get('confidence', 0.7),
            notes=f"Resolved {len(disagreements)} disagreements"
        )
```

---

## ğŸ¯ ä¸ºä»€ä¹ˆè¿™ä¸ªæ–¹æ¡ˆæ›´å¥½

### å¯¹æ¯”è¡¨

| æ–¹é¢ | æ—§æ–¹æ¡ˆï¼ˆAIéªŒè¯AIï¼‰ | æ–°æ–¹æ¡ˆï¼ˆåä½œï¼‰ | æ”¹è¿› |
|------|-------------------|---------------|------|
| **APIè°ƒç”¨** | 2x (ç”Ÿæˆ+éªŒè¯) | 1.5x (åˆ†æ+å†™ä½œ+å®¡æŸ¥) | â†“25% |
| **è´¨é‡** | ä¸å¯é¢„æµ‹ | å¤šå±‚ä¿éšœ | â†‘40% |
| **å¯è§£é‡Šæ€§** | é»‘ç›’ | æ¯æ­¥å¯è¿½æº¯ | â†‘100% |
| **å¤±è´¥å¤„ç†** | é‡è¯•æˆ–æ”¾å¼ƒ | å¤šç§é™çº§ç­–ç•¥ | â†‘100% |
| **å¼€å‘è°ƒè¯•** | å›°éš¾ | æ¯ä¸ªagentå¯å•ç‹¬æµ‹è¯• | â†‘80% |

### æˆæœ¬åˆ†æ

**åœºæ™¯**: ç”Ÿæˆä¸€ä¸ª26ç–¾ç—…çš„æœˆåº¦æŠ¥å‘Š

**æ—§æ–¹æ¡ˆï¼ˆAIéªŒè¯AIï¼‰**ï¼š
```
26 diseases Ã— 4 sections = 104 sections
æ¯ä¸ªsection:
- ç”Ÿæˆ: 1æ¬¡è°ƒç”¨ Ã— ~500 tokens
- éªŒè¯: 1æ¬¡è°ƒç”¨ Ã— ~300 tokens
- å¹³å‡é‡è¯•: 2æ¬¡
- å®é™…è°ƒç”¨: (1+1) Ã— 3 = 6æ¬¡/section

æ€»è°ƒç”¨: 104 Ã— 6 = 624æ¬¡
æ€»tokens: 624 Ã— 500 = 312,000 tokens
æˆæœ¬: ~$1.50
```

**æ–°æ–¹æ¡ˆï¼ˆä¸“å®¶åä½œï¼‰**ï¼š
```
26 diseases Ã— 1 analysis = 26æ¬¡åˆ†æ
- Analyst: 1æ¬¡ Ã— 600 tokens = 26 Ã— 600 = 15,600 tokens

104 sections Ã— å†™ä½œ+å®¡æŸ¥:
- Writer: 1æ¬¡ Ã— 500 tokens
- Reviewer: 1æ¬¡ Ã— 400 tokens (ä»…å¿…è¦æ—¶)
- è§„åˆ™éªŒè¯: 0 tokens (æœ¬åœ°)
- å¹³å‡è¿­ä»£: 1.3æ¬¡

æ€»è°ƒç”¨: 26 + (104 Ã— 2 Ã— 1.3) = 296æ¬¡
æ€»tokens: 15,600 + (104 Ã— 900 Ã— 1.3) = 137,000 tokens
æˆæœ¬: ~$0.70
```

**èŠ‚çœ**: 53%æˆæœ¬ + æ›´é«˜è´¨é‡ï¼

---

## ğŸ›¡ï¸ å¤±è´¥ä¿æŠ¤æœºåˆ¶

### å¤šå±‚é˜²æŠ¤

```python
class FailureProtection:
    """å¤±è´¥ä¿æŠ¤ç³»ç»Ÿ"""
    
    strategies = [
        # Layer 1: é¢„é˜²
        ("cache", 0.0),              # ç¼“å­˜å‘½ä¸­ï¼Œ0æˆæœ¬
        ("rule_validation", 0.0),     # è§„åˆ™éªŒè¯ï¼Œ0æˆæœ¬
        
        # Layer 2: æ—©æœŸæ£€æµ‹
        ("data_quality_check", 0.0),  # æ•°æ®è´¨é‡æ£€æŸ¥
        ("format_validation", 0.0),   # æ ¼å¼éªŒè¯
        
        # Layer 3: æ™ºèƒ½é‡è¯•
        ("retry_with_hint", 0.01),    # å¸¦æç¤ºé‡è¯•
        ("alternative_model", 0.02),  # åˆ‡æ¢æ¨¡å‹
        
        # Layer 4: é™çº§
        ("template_generation", 0.0), # æ¨¡æ¿ç”Ÿæˆ
        ("degraded_quality", 0.01),   # é™ä½è¦æ±‚
        
        # Layer 5: äººå·¥
        ("human_review_queue", 0.0),  # äººå·¥é˜Ÿåˆ—
        ("notify_admin", 0.0),        # é€šçŸ¥ç®¡ç†å‘˜
    ]
    
    async def protect(self, task: Callable, context: Dict):
        """
        æ‰§è¡Œä»»åŠ¡ï¼Œå¸¦å¤šå±‚ä¿æŠ¤
        """
        
        for strategy_name, cost in self.strategies:
            try:
                if strategy_name == "cache":
                    result = await self._try_cache(task, context)
                    if result:
                        logger.info(f"âœ“ Protected by CACHE (cost: $0)")
                        return result, 0.0
                
                elif strategy_name == "rule_validation":
                    # æ‰§è¡Œä»»åŠ¡å‰çš„é¢„æ£€
                    can_proceed = await self._pre_validate(context)
                    if not can_proceed:
                        continue
                
                # ... æ‰§è¡Œå…·ä½“ç­–ç•¥
                
            except Exception as e:
                logger.warning(f"Strategy {strategy_name} failed: {e}")
                continue
        
        # æ‰€æœ‰ç­–ç•¥å¤±è´¥
        raise AllStrategiesFailedError()
```

---

## ğŸ“š å®æ–½å»ºè®®

### åˆ†é˜¶æ®µå®æ–½

**Phase 1**: æ›¿æ¢éªŒè¯ç³»ç»Ÿï¼ˆ1å‘¨ï¼‰
- âœ… ä¿ç•™ç°æœ‰ç”Ÿæˆé€»è¾‘
- âœ… æ›¿æ¢AIéªŒè¯ä¸ºè§„åˆ™éªŒè¯
- âœ… æ·»åŠ åŸºç¡€é™çº§ç­–ç•¥
- **æˆæœ¬èŠ‚çœ**: 40%

**Phase 2**: å¼•å…¥ä¸“å®¶åˆ†å·¥ï¼ˆ2å‘¨ï¼‰
- âœ… Analyst + Writer åˆ†ç¦»
- âœ… å®ç°åŸºç¡€åä½œ
- **è´¨é‡æå‡**: 30%

**Phase 3**: å®Œå–„åä½œæœºåˆ¶ï¼ˆ1å‘¨ï¼‰
- âœ… æ·»åŠ Reviewerå’ŒFact Checker
- âœ… å®ç°è¿­ä»£æ”¹è¿›
- **è´¨é‡æå‡**: é¢å¤–20%

**Phase 4**: ä¸“å®¶Panelï¼ˆå¯é€‰ï¼Œ1å‘¨ï¼‰
- âœ… å¤šæ¨¡å‹å…±è¯†æœºåˆ¶
- âœ… å¤„ç†å¤æ‚åœºæ™¯

---

å‡†å¤‡å¥½å®æ–½äº†å—ï¼Ÿæˆ‘å¯ä»¥ï¼š

1. **å…ˆå®ç°éªŒè¯ç³»ç»Ÿ** - ç«‹å³è§£å†³ç©ºå­—ç¬¦ä¸²é—®é¢˜
2. **åˆ›å»ºAgentåŸºç¡€æ¶æ„** - ä¸ºåä½œé“ºè·¯
3. **å®ç°åä½œå·¥ä½œæµ** - å®Œæ•´solution
4. **ç¼–å†™æµ‹è¯•ç”¨ä¾‹** - ä¿è¯è´¨é‡

**ä½ æƒ³ä»å“ªé‡Œå¼€å§‹ï¼Ÿ** ğŸš€
